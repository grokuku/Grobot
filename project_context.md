#### Ce fichier sert de rÃ©fÃ©rence unique et doit Ãªtre fourni en intÃ©gralitÃ© au dÃ©but de chaque session.

---
### AXIOMES FONDAMENTAUX DE LA SESSION ###
---

#### **AXIOME 1 : COMPORTEMENTAL (L'Esprit de Collaboration)**

*   **Posture d'Expert** : J'agis en tant qu'expert en dÃ©veloppement logiciel, mÃ©ticuleux et proactif. J'anticipe les erreurs potentielles et je suggÃ¨re des points de vÃ©rification pertinents aprÃ¨s chaque modification.
*   **Principe de Moindre Intervention** : Je ne modifie que ce qui est strictement nÃ©cessaire pour rÃ©pondre Ã  la demande. Je n'introduis aucune modification (ex: refactoring, optimisation) non sollicitÃ©e.
*   **Partenariat Actif** : Je me positionne comme un partenaire de dÃ©veloppement qui analyse et propose, et non comme un simple exÃ©cutant.
*   **Gestion des AmbiguÃ¯tÃ©s** : Si une demande est ambiguÃ« ou si des informations nÃ©cessaires Ã  sa bonne exÃ©cution sont manquantes, je demanderai des clarifications avant de proposer une solution.

#### **AXIOME 2 : ANALYSE ET SÃ‰CURITÃ‰ (Aucune Action Aveugle)**

*   **Connaissance de l'Ã‰tat Actuel** : Avant TOUTE modification de fichier, si je ne dispose pas de son contenu intÃ©gral et Ã  jour dans notre session, je dois impÃ©rativement vous le demander. Une fois le contenu d'un fichier reÃ§u, je considÃ©rerai qu'il est Ã  jour et je ne le redemanderai pas, Ã  moins d'une notification explicite de votre part concernant une modification externe.
*   **Analyse PrÃ©alable Obligatoire** : Je ne proposerai jamais de commande de modification de code (ex: `sed`) sans avoir analysÃ© le contenu du fichier concernÃ© au prÃ©alable dans la session en cours.
*   **VÃ©rification Proactive des DÃ©pendances** : Ma base de connaissances s'arrÃªte dÃ©but 2023. Par consÃ©quent, avant d'intÃ©grer ou d'utiliser un nouvel outil, une nouvelle librairie ou un nouveau package, je dois systÃ©matiquement effectuer une recherche. Je rÃ©sumerai les points clÃ©s (version stable, breaking changes, nouvelles pratiques d'utilisation) dans le fichier `project_context.md`.
*   **Protection des DonnÃ©es** : Je ne proposerai jamais d'action destructive (ex: `rm`, `DROP TABLE`) sur des donnÃ©es en environnement de dÃ©veloppement sans proposer une alternative de contournement (ex: renommage, sauvegarde).

#### **AXIOME 3 : RESTITUTION DU CODE (ClartÃ© et FiabilitÃ©)**

*   **MÃ©thode 1 - Modification Atomique par `sed`** :
    *   **Usage** : Uniquement pour une modification simple, ciblÃ©e sur une seule ligne (modification de contenu, ajout ou suppression), et sans aucun risque d'erreur de syntaxe ou de contexte.
    *   **Format** : La commande `sed` doit Ãªtre fournie sur une seule ligne pour Git Bash, avec l'argument principal encapsulÃ© dans des guillemets simples (`'`). Le nouveau contenu du fichier ne sera pas affichÃ©.
    *   **ExclusivitÃ©** : Aucun autre outil en ligne de commande (`awk`, `patch`, `tee`, etc.) ne sera utilisÃ© pour la modification de fichiers.
*   **MÃ©thode 2 - Fichier Complet (Par DÃ©faut)** :
    *   **Usage** : C'est la mÃ©thode par dÃ©faut. Elle est obligatoire si une commande `sed` est trop complexe, risquÃ©e, ou si les modifications sont substantielles.
    *   **Format** : Je fournis le contenu intÃ©gral et mis Ã  jour du fichier.
*   **Formatage des Blocs de Restitution** :
    *   **Fichiers Markdown (`.md`)** : J'utiliserai un bloc de code markdown (```md) non indentÃ©. Le contenu intÃ©gral du fichier sera systÃ©matiquement indentÃ© de quatre espaces Ã  l'intÃ©rieur de ce bloc.
    *   **Autres Fichiers (Code, Config, etc.)** : J'utiliserai un bloc de code standard (```langue). Les balises d'ouverture et de fermeture ne seront jamais indentÃ©es, mais le code Ã  l'intÃ©rieur le sera systÃ©matiquement de quatre espaces.

#### **AXIOME 4 : WORKFLOW (Un Pas AprÃ¨s l'Autre)**

1.  **Validation Explicite** : AprÃ¨s chaque proposition de modification (que ce soit par `sed` ou par fichier complet), je marque une pause. J'attends votre accord explicite ("OK", "AppliquÃ©", "ValidÃ©", etc.) avant de passer Ã  un autre fichier ou Ã  une autre tÃ¢che.
2.  **Documentation Continue des DÃ©pendances** : Si la version d'une dÃ©pendance s'avÃ¨re plus rÃ©cente que ma base de connaissances, je consigne son numÃ©ro de version et les notes d'utilisation pertinentes dans le fichier `project_context.md`.
3.  **Documentation de Fin de FonctionnalitÃ©** : Ã€ la fin du dÃ©veloppement d'une fonctionnalitÃ© majeure et aprÃ¨s votre validation finale, je proposerai de maniÃ¨re proactive la mise Ã  jour des fichiers de suivi du projet, notamment `project_context.md` et `features.md`.

#### **AXIOME 5 : LINGUISTIQUE (Bilinguisme Strict)**

*   **Nos Interactions** : Toutes nos discussions, mes explications et mes questions se dÃ©roulent exclusivement en **franÃ§ais**.
*   **Le Produit Final** : Absolument tout le livrable (code, commentaires, docstrings, noms de variables, logs, textes d'interface, etc.) est rÃ©digÃ© exclusivement en **anglais**.

---
### FIN DES AXIOMES FONDAMENTAUX ###
---


---
### 1. Vision et Objectifs du Projet

Le projet "GroBot" vise Ã  crÃ©er une plateforme d'hÃ©bergement et de gestion **pour une flotte de bots Discord entiÃ¨rement indÃ©pendants**. Il ne s'agit pas d'un seul bot multi-personnalitÃ©s, mais d'une infrastructure capable de faire tourner de multiples processus de bots en parallÃ¨le.

L'objectif principal est une **administrabilitÃ© dynamique** via une **interface web moderne de type SPA (Single Page Application)**, permettant l'ajout, la configuration ou la dÃ©sactivation d'un bot Ã  chaud, **sans nÃ©cessiter le redÃ©marrage des bots dÃ©jÃ  en cours d'exÃ©cution**.

---

## 2. Principes d'Architecture Fondamentaux

1.  **Architecture d'Application CombinÃ©e :** Pour simplifier le dÃ©ploiement et Ã©liminer les problÃ¨mes de CORS, le Frontend et le Backend sont servis par un **unique service conteneurisÃ©**. Nginx agit comme reverse proxy : il sert les fichiers statiques du frontend et redirige les requÃªtes API vers le processus FastAPI tournant dans le mÃªme conteneur.
2.  **Configuration CentralisÃ©e en Base de DonnÃ©es :** Toute la configuration spÃ©cifique Ã  un bot est stockÃ©e **uniquement** dans PostgreSQL. Le fichier `.env` est rÃ©servÃ© Ã  la configuration de la plateforme.
3.  **Isolation par Processus :** Chaque bot actif tourne dans son propre processus systÃ¨me, gÃ©rÃ© par le service `discord-bot-launcher`.
4.  **Isolation des DonnÃ©es (MÃ©moire) :** La mÃ©moire Ã  long terme (LTM) est stockÃ©e dans ChromaDB au sein d'une **collection dÃ©diÃ©e par bot**.
5.  **Communication Conteneur-HÃ´te :** L'URL `http://host.docker.internal:[port]` est la valeur standard pour qu'un conteneur accÃ¨de Ã  un service sur l'hÃ´te. Les services communiquent entre eux via leur nom de service (ex: `http://app:8000`, `http://ollama:11434`).
6.  **Gestion du SchÃ©ma de Base de DonnÃ©es :** Alembic est la **seule autoritÃ©** pour la gestion du schÃ©ma de la base de donnÃ©es. L'appel `Base.metadata.create_all()` n'est pas utilisÃ© en production pour Ã©viter tout conflit. Pour les relations "plusieurs-Ã -plusieurs" avec des donnÃ©es additionnelles (ex: la configuration d'un outil pour un bot), le patron de conception **Association Object** de SQLAlchemy est utilisÃ©.
7.  **Structure des Chemins dans le Conteneur `app` :** En raison de la configuration Docker, le rÃ©pertoire `app` du projet est copiÃ© dans le rÃ©pertoire `/app` du conteneur. Par consÃ©quent, le chemin d'accÃ¨s absolu pour les fichiers du projet (comme `alembic.ini`) Ã  l'intÃ©rieur du conteneur est systÃ©matiquement `/app/app/...`. Cette convention doit Ãªtre respectÃ©e pour toutes les commandes `docker-compose exec`.
8.  **Architecture de Prompt Hybride :** Le prompt systÃ¨me final envoyÃ© au LLM est assemblÃ© dynamiquement par la logique mÃ©tier. Il combine des **directives fondamentales non-modifiables** (codÃ©es en dur pour tous les bots) avec le **contexte d'exÃ©cution dynamique** (serveur/salon Discord, fichiers joints, mÃ©moire LTM) et la **personnalitÃ© spÃ©cifique au bot** (stockÃ©e en base de donnÃ©es).
9.  **Agentique et ExÃ©cution des Outils CÃ´tÃ© Client :** La boucle de l'agent (LLM -> appel d'outil -> LLM) est gÃ©rÃ©e par le client, c'est-Ã -dire `bot_process.py`, et non par le backend. Cette approche garantit la **sÃ©curitÃ© maximale** (le token Discord ne quitte jamais son processus) et permet l'implÃ©mentation d'**outils internes** qui interagissent directement avec l'objet client `discord.py`. Les outils externes (MCP) sont appelÃ©s via un **endpoint API proxy dÃ©diÃ© (`/api/tools/call`)** qui centralise la logique de communication.
10. **MÃ©moire Utilisateur Ã  Deux Composants :** La connaissance persistante du bot sur les utilisateurs est divisÃ©e en deux types de donnÃ©es distincts : les **Profils Utilisateurs** (contenant des directives comportementales modifiables par un administrateur) et les **Notes Utilisateurs** (contenant des faits textuels avec un score de fiabilitÃ©, que le bot peut crÃ©er et lire lui-mÃªme via ses outils).
11. **Architecture d'Agent SpÃ©cialisÃ© ("ChaÃ®ne de Montage") :** Pour fiabiliser l'utilisation des outils, le traitement d'un message est dÃ©composÃ© en une sÃ©rie d'appels LLM spÃ©cialisÃ©s. Chaque LLM a un rÃ´le unique et dÃ©fini (Gardien, Planificateur, SynthÃ©tiseur, etc.). L'orchestration de cette chaÃ®ne est gÃ©rÃ©e par le backend.
12. **SpÃ©cialisation des ModÃ¨les LLM par CatÃ©gorie de TÃ¢che :** Pour optimiser les performances et les coÃ»ts, la configuration LLM est segmentÃ©e en trois catÃ©gories fonctionnelles, chacune pouvant Ãªtre assignÃ©e Ã  un serveur, un modÃ¨le et une fenÃªtre de contexte spÃ©cifiques. Ces catÃ©gories sont :
    *   **DÃ©cisionnel :** ModÃ¨les rapides pour des tÃ¢ches de classification ou de filtrage (ex: `Gatekeeper`).
    *   **Outils :** ModÃ¨les fiables avec un bon raisonnement logique pour la gÃ©nÃ©ration de JSON et l'appel d'outils (ex: `Parameter Extractor`).
    *   **Output Client :** ModÃ¨les puissants et crÃ©atifs pour la gÃ©nÃ©ration des rÃ©ponses finales Ã  l'utilisateur (ex: `Synthesizer`).

---

## 3. Architecture et Technologies

### 3.1. Technologies Principales
*   **Orchestration :** Docker, Docker Compose
*   **Backend API :** FastAPI
*   **Serveur Applicatif :** Nginx (agissant comme serveur web statique et reverse proxy) et Uvicorn (pour l'API FastAPI).
*   **Gestion des processus Bots :** Python 3.11+, `subprocess`
*   **Base de DonnÃ©es Relationnelle (Gestion) :** PostgreSQL (via SQLAlchemy)
*   **Migration de Base de DonnÃ©es :** Alembic (pour les mises Ã  jour de schÃ©ma non-destructives)
*   **Base de DonnÃ©es Vectorielle (MÃ©moire LTM IsolÃ©e) :** ChromaDB
*   **Interaction LLM :** `requests`, `httpx`, `ollama-python`
*   **Client Discord :** `discord.py`
*   **TÃ¢ches Asynchrones :** Celery, Redis

### 3.2. Arborescence ComplÃ¨te du Projet et RÃ´le des Fichiers

```    ğŸ“ GroBot/
    â”œâ”€ ğŸ“„ .dockerignore                 # Ignore les fichiers non nÃ©cessaires lors de la construction de l'image Docker.
    â”œâ”€ ğŸ“„ .env.example                  # Fichier d'exemple pour les variables d'environnement.
    â”œâ”€ ğŸ“„ docker-compose.yml            # DÃ©finit et orchestre tous les services de l'application.
    â”œâ”€ ğŸ“„ Dockerfile                    # Recette multi-stage pour l'image 'app' (API+Frontend).
    â”œâ”€ ğŸ“„ features.md                   # Suivi de haut niveau des fonctionnalitÃ©s.
    â”œâ”€ ğŸ“„ project_context.md            # Ce fichier, source de vÃ©ritÃ© du projet.
    â”œâ”€ ğŸ“„ requirements.txt              # DÃ©pendances Python pour le service 'app'.
    â”‚
    â”œâ”€ ğŸ“ app/                           # CÅ“ur du Backend : API et logique mÃ©tier.
    â”‚  â”œâ”€ ğŸ“„ __init__.py                 # Marque le dossier comme un package Python.
    â”‚  â”œâ”€ ğŸ“„ alembic.ini                 # Fichier de configuration pour Alembic.
    â”‚  â”œâ”€ ğŸ“„ config.py                   # Charge les variables d'environnement via Pydantic.
    â”‚  â”œâ”€ ğŸ“„ main.py                     # Point d'entrÃ©e de l'API FastAPI, gÃ¨re le cycle de vie et les routeurs.
    â”‚  â”‚
    â”‚  â”œâ”€ ğŸ“ alembic/                    # Dossier pour la gestion des migrations de base de donnÃ©es.
    â”‚  â”‚  â”œâ”€ ğŸ“„ README                    # Instructions pour Alembic.
    â”‚  â”‚  â”œâ”€ ğŸ“„ env.py                    # Script de configuration d'environnement pour Alembic.
    â”‚  â”‚  â”œâ”€ ğŸ“„ script.py.mako            # Template pour les nouveaux scripts de migration.
    â”‚  â”‚  â””â”€ ğŸ“ versions/               # Contient tous les scripts de migration gÃ©nÃ©rÃ©s.
    â”‚  â”‚     â””â”€ ... (fichiers de migration auto-gÃ©nÃ©rÃ©s)
    â”‚  â”‚
    â”‚  â”œâ”€ ğŸ“ api/                        # Contient les routeurs FastAPI (endpoints).
    â”‚  â”‚  â”œâ”€ ğŸ“„ __init__.py               # Marque le dossier comme un package Python.
    â”‚  â”‚  â”œâ”€ ğŸ“„ bots_api.py               # API pour la gestion des bots (CRUD).
    â”‚  â”‚  â”œâ”€ ğŸ“„ bots_api.py.bak           # Fichier de sauvegarde, non utilisÃ©.
    â”‚  â”‚  â”œâ”€ ğŸ“„ chat_api.py               # API pour l'orchestration des agents et le chat.
    â”‚  â”‚  â”œâ”€ ğŸ“„ files_api.py              # API pour la gestion des fichiers.
    â”‚  â”‚  â”œâ”€ ğŸ“„ llm_api.py                # API pour l'interaction avec les LLMs (ex: lister les modÃ¨les).
    â”‚  â”‚  â”œâ”€ ğŸ“„ mcp_api.py                # API pour la gestion des serveurs MCP.
    â”‚  â”‚  â”œâ”€ ğŸ“„ settings_api.py           # API pour les paramÃ¨tres globaux.
    â”‚  â”‚  â”œâ”€ ğŸ“„ tools_api.py              # API proxy pour l'exÃ©cution des outils externes (MCP).
    â”‚  â”‚  â”œâ”€ ğŸ“„ user_profiles_api.py      # API pour la gestion des profils et notes utilisateurs.
    â”‚  â”‚  â””â”€ ğŸ“„ workflows_api.py          # API pour la gestion des workflows (CRUD et exÃ©cution).
    â”‚  â”‚
    â”‚  â”œâ”€ ğŸ“ core/                       # Logique mÃ©tier principale de l'application.
    â”‚  â”‚  â”œâ”€ ğŸ“„ __init__.py               # Marque le dossier comme un package Python.
    â”‚  â”‚  â”œâ”€ ğŸ“„ agent_logic.py.old        # Fichier de sauvegarde, non utilisÃ©.
    â”‚  â”‚  â”œâ”€ ğŸ“„ agent_orchestrator.py     # Orchestre la chaÃ®ne d'appels aux agents spÃ©cialisÃ©s.
    â”‚  â”‚  â”œâ”€ ğŸ“„ llm_manager.py            # GÃ¨re les instances de clients LLM et les interactions.
    â”‚  â”‚  â”œâ”€ ğŸ“„ websocket_manager.py      # GÃ¨re les connexions WebSocket persistantes avec les clients bot.
    â”‚  â”‚  â””â”€ ğŸ“ agents/                 # Contient la logique pour chaque agent LLM spÃ©cialisÃ©.
    â”‚  â”‚     â”œâ”€ ğŸ“„ __init__.py           # Marque le dossier comme un package Python.
    â”‚  â”‚     â”œâ”€ ğŸ“„ acknowledger.py       # Agent pour gÃ©nÃ©rer les messages d'attente.
    â”‚  â”‚     â”œâ”€ ğŸ“„ archivist.py          # Agent pour archiver les informations en mÃ©moire.
    â”‚  â”‚     â”œâ”€ ğŸ“„ clarifier.py          # Agent pour demander des informations manquantes.
    â”‚  â”‚     â”œâ”€ ğŸ“„ gatekeeper.py         # Agent pour dÃ©cider si le bot doit rÃ©pondre.
    â”‚  â”‚     â”œâ”€ ğŸ“„ parameter_extractor.py# Agent pour extraire les paramÃ¨tres des outils.
    â”‚  â”‚     â”œâ”€ ğŸ“„ planner.py            # Agent pour crÃ©er le plan d'exÃ©cution des outils.
    â”‚  â”‚     â”œâ”€ ğŸ“„ prompts.py            # Centralise tous les prompts systÃ¨me des agents.
    â”‚  â”‚     â”œâ”€ ğŸ“„ synthesizer.py        # Agent pour formuler la rÃ©ponse finale.
    â”‚  â”‚     â””â”€ ğŸ“„ tool_identifier.py    # Agent pour identifier les outils nÃ©cessaires.
    â”‚  â”‚
    â”‚  â”œâ”€ ğŸ“ database/                   # Module pour l'accÃ¨s aux bases de donnÃ©es.
    â”‚  â”‚  â”œâ”€ ğŸ“„ __init__.py               # Marque le dossier comme un package Python.
    â”‚  â”‚  â”œâ”€ ğŸ“„ base.py                   # DÃ©finit la base dÃ©clarative SQLAlchemy.
    â”‚  â”‚  â”œâ”€ ğŸ“„ chroma_manager.py         # GÃ¨re les interactions avec ChromaDB (mÃ©moire vectorielle).
    â”‚  â”‚  â”œâ”€ ğŸ“„ crud_bots.py              # Fonctions CRUD pour les bots.
    â”‚  â”‚  â”œâ”€ ğŸ“„ crud_channel_settings.py  # Fonctions CRUD pour les permissions par salon.
    â”‚  â”‚  â”œâ”€ ğŸ“„ crud_files.py             # Fonctions CRUD pour les fichiers.
    â”‚  â”‚  â”œâ”€ ğŸ“„ crud_mcp.py               # Fonctions CRUD pour les serveurs MCP.
    â”‚  â”‚  â”œâ”€ ğŸ“„ crud_settings.py          # Fonctions CRUD pour les paramÃ¨tres globaux.
    â”‚  â”‚  â”œâ”€ ğŸ“„ crud_user_notes.py        # Fonctions CRUD pour les notes sur les utilisateurs.
    â”‚  â”‚  â”œâ”€ ğŸ“„ crud_user_profiles.py     # Fonctions CRUD pour les profils utilisateurs.
    â”‚  â”‚  â”œâ”€ ğŸ“„ crud_workflows.py         # Fonctions CRUD pour les workflows.
    â”‚  â”‚  â”œâ”€ ğŸ“„ redis_session.py          # GÃ¨re la connexion au client Redis.
    â”‚  â”‚  â”œâ”€ ğŸ“„ sql_models.py             # DÃ©finit les modÃ¨les de table SQLAlchemy.
    â”‚  â”‚  â””â”€ ğŸ“„ sql_session.py            # GÃ¨re la session de base de donnÃ©es SQL.
    â”‚  â”‚
    â”‚  â”œâ”€ ğŸ“ schemas/                    # Contient les schÃ©mas Pydantic pour la validation des donnÃ©es API.
    â”‚  â”‚  â”œâ”€ ğŸ“„ __init__.py               # Marque le dossier comme un package Python.
    â”‚  â”‚  â”œâ”€ ğŸ“„ bot_schemas.py            # SchÃ©mas Pydantic pour les bots.
    â”‚  â”‚  â”œâ”€ ğŸ“„ chat_schemas.py           # SchÃ©mas Pydantic pour le chat et les agents.
    â”‚  â”‚  â”œâ”€ ğŸ“„ file_schemas.py           # SchÃ©mas Pydantic pour les fichiers.
    â”‚  â”‚  â”œâ”€ ğŸ“„ mcp_schemas.py            # SchÃ©mas Pydantic pour les serveurs MCP.
    â”‚  â”‚  â”œâ”€ ğŸ“„ settings_schema.py        # SchÃ©mas Pydantic pour les paramÃ¨tres.
    â”‚  â”‚  â”œâ”€ ğŸ“„ user_note_schemas.py      # SchÃ©mas Pydantic pour les notes utilisateurs.
    â”‚  â”‚  â”œâ”€ ğŸ“„ user_profile_schemas.py   # SchÃ©mas Pydantic pour les profils utilisateurs.
    â”‚  â”‚  â””â”€ ğŸ“„ workflow_schemas.py       # SchÃ©mas Pydantic pour les workflows.
    â”‚  â”‚
    â”‚  â””â”€ ğŸ“ worker/                     # Configuration pour les tÃ¢ches de fond (Celery).
    â”‚     â”œâ”€ ğŸ“„ __init__.py               # Marque le dossier comme un package Python.
    â”‚     â”œâ”€ ğŸ“„ celery_app.py             # DÃ©finit l'instance de l'application Celery.
    â”‚     â””â”€ ğŸ“„ tasks.py                  # DÃ©finit les tÃ¢ches Celery (ex: archivage, exÃ©cution de workflows).
    â”‚
    â”œâ”€ ğŸ“ chromadb_overriden/
    â”‚  â””â”€ ğŸ“„ Dockerfile                  # Personnalise l'image ChromaDB (ex: ajout de 'curl').
    â”‚
    â”œâ”€ ğŸ“ discord_bot_launcher/         # Service isolÃ© qui gÃ¨re les processus des bots Discord.
    â”‚  â”œâ”€ ğŸ“„ bot_process.py              # Point d'entrÃ©e du client Discord, initialise les handlers.
    â”‚  â”œâ”€ ğŸ“„ bot_process.py.old          # Fichier de sauvegarde, non utilisÃ©.
    â”‚  â”œâ”€ ğŸ“„ Dockerfile                  # Image Docker pour le service launcher.
    â”‚  â”œâ”€ ğŸ“„ launcher.py                 # Script qui surveille l'API et lance/arrÃªte les bots.
    â”‚  â”œâ”€ ğŸ“„ requirements.txt            # DÃ©pendances Python pour le service launcher.
    â”‚  â””â”€ ğŸ“ client/                     # Logique modulaire du client Discord.
    â”‚     â”œâ”€ ğŸ“„ __init__.py               # Marque le dossier comme un package Python.
    â”‚     â”œâ”€ ğŸ“„ api_client.py             # Centralise toutes les requÃªtes vers l'API backend.
    â”‚     â”œâ”€ ğŸ“„ discord_ui.py             # Fonctions utilitaires pour l'UI de Discord (rÃ©actions, etc.).
    â”‚     â””â”€ ğŸ“„ event_handler.py          # Contient la logique principale `on_message`.
    â”‚
    â”œâ”€ ğŸ“ frontend/                     # Application combinÃ©e (Nginx + SPA).
    â”‚  â”œâ”€ ğŸ“„ entrypoint.sh               # Script de dÃ©marrage pour le conteneur 'app' (nginx + uvicorn).
    â”‚  â”œâ”€ ğŸ“„ nginx.conf                  # Configuration Nginx (reverse proxy et fichiers statiques).
    â”‚  â””â”€ ğŸ“ src/                        # Code source JavaScript pour l'interface utilisateur.
    â”‚     â”œâ”€ ğŸ“„ api.js                    # Fonctions utilitaires pour les appels API.
    â”‚     â”œâ”€ ğŸ“„ events.js                 # Gestionnaires d'Ã©vÃ©nements (formulaires, WebSocket).
    â”‚     â”œâ”€ ğŸ“„ index.html                # Structure HTML de l'application.
    â”‚     â”œâ”€ ğŸ“„ main.js                   # Point d'entrÃ©e JavaScript, initialisation et routage.
    â”‚     â”œâ”€ ğŸ“„ style.css                 # Styles CSS.
    â”‚     â”œâ”€ ğŸ“„ ui.js                     # Fonctions pour manipuler le DOM et mettre Ã  jour l'UI.
    â”‚     â””â”€ ğŸ“„ workflow_editor.js        # Module UI pour l'Ã©diteur de workflows.
    â”‚
    â””â”€ ğŸ“ grobot_tools/                 # Service MCP contenant les outils standards.
        â”œâ”€ ğŸ“„ Dockerfile                  # Dockerfile pour le service d'outils.
        â”œâ”€ ğŸ“„ requirements.txt            # DÃ©pendances Python pour les outils.
        â”œâ”€ ğŸ“„ supervisord.conf            # Configuration Supervisor pour lancer les outils.
        â”œâ”€ ğŸ“ file_tools/                 # Outils de gestion de fichiers.
        â”‚  â””â”€ ğŸ“„ server.py                 # Point d'entrÃ©e du serveur MCP pour les outils de fichiers.
        â””â”€ ğŸ“ time_tool/                  # Outils liÃ©s au temps.
        â””â”€ ğŸ“„ server.py                 # Point d'entrÃ©e du serveur MCP pour l'outil de temps.
```

---

## 4. Vision de l'Interface Cible (Post-Refonte)

*   **Disposition GÃ©nÃ©rale :** Une application Ã  deux colonnes principales.
    *   **Colonne de Gauche (Sidebar, redimensionnable) :**
        *   **Titre :** "GroBot".
        *   **Liste des Bots :** Affiche tous les bots configurÃ©s. Chaque Ã©lÃ©ment montre le nom du bot et son Ã©tat (en ligne/hors ligne).
        *   **Boutons d'Action Globale :**
            *   Un bouton pour "Add Bot".
            *   Un bouton "roue crantÃ©e" pour "Configuration Globale".
    *   **Colonne de Droite (Contenu Principal) :**
        *   **En-tÃªte :** Affiche le nom du bot/de la vue actuellement sÃ©lectionnÃ©(e), et des contrÃ´les (ex: boutons de thÃ¨me).
        *   **Zone de Contenu :** Affiche la vue sÃ©lectionnÃ©e pour un bot via un systÃ¨me d'onglets. Les onglets principaux sont :
            *   **Test Chat :** Une interface pour interagir directement avec le bot.
            *   **Logs :** Un dashboard de logs en temps rÃ©el.
            *   **Settings :** Le formulaire de configuration du bot, incluant les nouveaux rÃ©glages LLM par catÃ©gorie (serveur, modÃ¨le, contexte) et une nouvelle section pour les **permissions par salon**, affichant une liste des salons Discord du bot avec des interrupteurs pour contrÃ´ler l'accÃ¨s et l'Ã©coute passive pour chacun.
            *   **Files :** Le gestionnaire de fichiers du bot.
            *   **Memory :** Une vue de la mÃ©moire vectorielle du bot.
            *   **Knowledge Base :** Une interface pour gÃ©rer les connaissances du bot sur les utilisateurs. Cette vue affiche une barre de recherche et, par dÃ©faut, la liste des utilisateurs connus par ce bot. Un clic sur un utilisateur ou une recherche rÃ©ussie affiche la vue dÃ©taillÃ©e du profil et des notes de cet utilisateur.
            *   **Workflows :** Une vue pour gÃ©rer les automatisations. Affiche une grille de "cartes", chacune reprÃ©sentant un workflow avec des options pour l'exÃ©cuter, le modifier ou le supprimer.

---

## 6. Documentation : Le Standard Model Context Protocol (MCP)

*   **Date d'Adoption :** 2025-08-15
*   **Source de VÃ©ritÃ© :** [DÃ©pÃ´t GitHub Officiel](https://github.com/modelcontextprotocol/modelcontextprotocol) et [Documentation](https://modelcontextprotocol.info/docs/)

Cette section annule et remplace toute implÃ©mentation prÃ©cÃ©dente d'outils. Le projet adopte le standard ouvert et officiel MCP pour l'intÃ©gration des outils.

### 6.1. Principes Fondamentaux

1.  **Communication StandardisÃ©e :** Toutes les interactions entre un client (notre `bot_process`) et un serveur d'outils (ex: `mcp_time_tool`) **DOIVENT** utiliser le protocole **JSON-RPC 2.0**.
2.  **MÃ©thodes RPC SpÃ©cifiÃ©es :** Le standard dÃ©finit des noms de mÃ©thodes prÃ©cis que les serveurs doivent implÃ©menter et que les clients doivent appeler. Les deux mÃ©thodes fondamentales pour les outils sont `tools/list` et `tools/call`.
3.  **DÃ©finition via JSON Schema :** La "signature" d'un outil (son nom, sa description, ses paramÃ¨tres et leurs types) est dÃ©crite de maniÃ¨re structurÃ©e via une JSON Schema. C'est ce qui permet une dÃ©couverte vÃ©ritablement automatique et fiable.

### 6.2. MÃ©thodes RPC Standard

#### 6.2.1. `tools/list`

*   **RÃ´le :** Permet Ã  client de dÃ©couvrir les outils disponibles sur un serveur.
*   **RequÃªte du Client :**
    ```json
    {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "tools/list",
        "params": {}
    }
    ```
*   **RÃ©ponse du Serveur :**
    ```json
    {
        "jsonrpc": "2.0",
        "id": 1,
        "result": {
            "tools": [
                // ... liste des dÃ©finitions d'outils ...
            ]
        }
    }
    ```

#### 6.2.2. `tools/call`

*   **RÃ´le :** Permet Ã  client d'exÃ©cuter un outil spÃ©cifique avec des arguments.
*   **RequÃªte du Client :**
    ```json
    {
        "jsonrpc": "2.0",
        "id": 2,
        "method": "tools/call",
        "params": {
            "name": "tool_name_to_call",
            "arguments": {
                "param1_name": "value1",
                "param2_name": 123
            }
        }
    }
    ```
*   **RÃ©ponse du Serveur :**
    ```json
    {
        "jsonrpc": "2.0",
        "id": 2,
        "result": {
            "content": [
                {
                    "type": "text",
                    "text": "The result of the tool execution."
                }
            ]
        }
    }
    ```
    
### 6.3. Format de DÃ©finition d'un Outil

Chaque outil retournÃ© par `tools/list` **DOIT** suivre le format JSON Schema suivant, avec la clÃ© `inputSchema` pour les paramÃ¨tres.

**Exemple pour `get_current_time` :**
```json
{
    "name": "get_current_time",
    "title": "Get Current Time",
    "description": "Returns the current server date and time. Use this for any questions about the current time, date, or day of the week.",
    "inputSchema": {
        "type": "object",
        "properties": {}
    }
}
```

### 6.4. ImplÃ©mentations MCP Connues

Pour garantir l'interopÃ©rabilitÃ©, GroBot s'appuie sur des serveurs d'outils qui respectent le standard MCP. La documentation de rÃ©fÃ©rence pour ces serveurs est essentielle pour comprendre les outils disponibles.

*   **MCP_GenImage:** Service avancÃ© de gÃ©nÃ©ration d'images.
    *   *[Lien vers le project_context.md de MCP_GenImage Ã  insÃ©rer ici]*

---

## 7. Ã‰tat Actuel et Plan d'Action

### 7.1. Bugs Connus et RÃ©gression (Issues Actuellement Ouvertes)

*   **Timeout de la commande `/prompt_generator` et Ã‰chec de l'AutocomplÃ©tion des Styles (`app/api/tools_api.py`, `discord_bot_launcher/client/event_handler.py`)**
    *   **Description :** La commande `/prompt_generator` Ã©choue par intermittence avec une erreur "Cette interaction a Ã©chouÃ©" (timeout de 3 secondes de Discord). SimultanÃ©ment, la liste des styles pour l'autocomplÃ©tion est souvent vide. Le bug ne se produit que lorsque le cache des dÃ©finitions d'outils du backend est expirÃ©.
    *   **HypothÃ¨se :** Il s'agit d'une "course au dÃ©lai". La dÃ©couverte des outils, qui interroge tous les serveurs MCP, prend parfois trop de temps, mÃªme en local, et dÃ©passe les dÃ©lais stricts de Discord pour la rÃ©ponse Ã  une interaction.
    *   **Plan d'action :** L'investigation est en cours. La premiÃ¨re Ã©tape convenue est d'appliquer une version instrumentÃ©e de `app/api/tools_api.py` qui ajoute des logs de performance dÃ©taillÃ©s. Ces logs permettront de mesurer prÃ©cisÃ©ment le temps pris par les appels rÃ©seau et de confirmer ou d'infirmer l'hypothÃ¨se de la latence avant d'appliquer un correctif.
    *   **Statut :** EN COURS D'INVESTIGATION.

*   **ProblÃ¨me d'Interface Utilisateur dans l'Onglet "Memory" (`frontend/src/ui.js`, `app/api/chat_api.py`)**
    *   **Description :** L'onglet "Memory" dans l'interface utilisateur ne fonctionne pas. Le code de `frontend/src/ui.js` contient une section commentÃ©e ou une rÃ©fÃ©rence Ã  `fetchBotMemory` qui ne semble pas Ãªtre correctement appelÃ©e ou rendue.
    *   **Impact :** L'utilisateur ne peut pas consulter la mÃ©moire conversationnelle du bot.
    *   **Statut :** NON RÃ‰SOLU.

*   **Outils non Fonctionnels dans l'Interface de Test (`frontend/src/ui.js`)**
    *   **Description :** Les outils (comme `generate_image` ou `describe_image`) ne fonctionnent pas lorsqu'ils sont appelÃ©s depuis l'interface de test chat dans le frontend. Le code dans `handleTestChatSubmit` ne semble pas gÃ©rer l'exÃ©cution des outils directement.
    *   **Impact :** L'utilisateur ne peut pas tester les fonctionnalitÃ©s des outils via l'interface web.
    *   **Statut :** NON RÃ‰SOLU.

*   **Suppression de Bot Impossible (`frontend/src/ui.js`, `app/api/bots_api.py`)**
    *   **Description :** La fonctionnalitÃ© de suppression d'un bot n'est pas implÃ©mentÃ©e dans l'interface utilisateur (pas de bouton ou de logique de gestion pour la suppression) ni dans l'API backend (`bots_api.py`). Bien que le `crud_bots.delete_bot` existe, il n'est pas appelÃ© par une route API.
    *   **Impact :** Les utilisateurs ne peuvent pas supprimer des bots via l'interface web.
    *   **Statut :** NON RÃ‰SOLU.

### 7.2. FonctionnalitÃ©s RÃ©cemment ImplÃ©mentÃ©es

*   **Gestion Fine des Permissions par Salon**
    *   **Analyse :** Le simple interrupteur global "Passive Listening" Ã©tait insuffisant pour tester le `Gatekeeper` dans un environnement de production sans perturber les utilisateurs. Un besoin a Ã©tÃ© identifiÃ© pour contrÃ´ler le comportement du bot de maniÃ¨re granulaire, salon par salon, avec deux niveaux de contrÃ´le : un blocage total ("Access") et un contrÃ´le de l'Ã©coute passive ("Passive Listening").
    *   **RÃ©solution :** La fonctionnalitÃ© a Ã©tÃ© implÃ©mentÃ©e sur l'ensemble de la pile. **1. Base de DonnÃ©es :** Une nouvelle table `channel_settings` a Ã©tÃ© ajoutÃ©e via un modÃ¨le SQLAlchemy (`sql_models.py`) et une migration Alembic pour stocker les permissions. **2. Backend :** Un nouveau fichier CRUD (`crud_channel_settings.py`) et de nouveaux schÃ©mas Pydantic (`bot_schemas.py`) ont Ã©tÃ© crÃ©Ã©s. Deux nouveaux endpoints ont Ã©tÃ© ajoutÃ©s Ã  `bots_api.py` : un `POST` pour sauvegarder les permissions et un `GET` qui utilise une requÃªte WebSocket vers le client Discord pour obtenir la liste des salons en temps rÃ©el et la fusionner avec les permissions stockÃ©es. **3. Frontend :** L'interface utilisateur dans l'onglet "Settings" (`ui.js`) a Ã©tÃ© refondue pour remplacer l'ancien interrupteur par un tableau affichant chaque salon avec ses deux interrupteurs. Les appels API (`api.js`) et les gestionnaires d'Ã©vÃ©nements (`events.js`, `main.js`) correspondants ont Ã©tÃ© implÃ©mentÃ©s pour rendre l'interface interactive. **4. Client Discord :** La logique au dÃ©but de la fonction `on_message` dans `event_handler.py` a Ã©tÃ© entiÃ¨rement revue pour lire les permissions par salon depuis la configuration du bot mise en cache et appliquer les rÃ¨gles d'accÃ¨s et d'Ã©coute passive avant tout traitement.
    *   **Statut :** IMPLÃ‰MENTÃ‰.

*   **ImplÃ©mentation du Logging des Interactions LLM**
    *   **Analyse :** Un besoin crucial de dÃ©bogage a Ã©tÃ© identifiÃ© : visualiser les prompts exacts envoyÃ©s aux LLM et les rÃ©ponses brutes reÃ§ues. Cela est essentiel pour comprendre le comportement des agents et corriger les problÃ¨mes de contexte.
    *   **RÃ©solution :** Un systÃ¨me de logging dÃ©diÃ© a Ã©tÃ© implÃ©mentÃ©. **1. Infrastructure :** Un rÃ©pertoire `logs/` a Ã©tÃ© crÃ©Ã© et montÃ© via un volume dans `docker-compose.yml`. **2. Backend :** Une fonction de logging dÃ©diÃ©e (`log_llm_interaction`) a Ã©tÃ© ajoutÃ©e dans `app/core/llm_manager.py`. Elle Ã©crit chaque interaction (prompt et rÃ©ponse) dans un fichier `logs/llm_interactions.md` dans un format Markdown lisible. Cette fonction est appelÃ©e depuis les points d'entrÃ©e `call_llm` et `call_llm_stream`, garantissant que tous les appels LLM, quelle que soit leur catÃ©gorie (dÃ©cisionnel, outils, output), sont tracÃ©s.
    *   **Statut :** IMPLÃ‰MENTÃ‰.

*   **AmÃ©lioration de la Visualisation des Ã‰valuations LLM : Ajout du ModÃ¨le et du Contexte**
    *   **Analyse :** La fonctionnalitÃ© de visualisation des rÃ©sultats d'Ã©valuation Ã©tait fonctionnelle mais incomplÃ¨te. Elle n'affichait pas les informations cruciales que sont le nom du modÃ¨le et la taille de la fenÃªtre de contexte utilisÃ©s pour chaque test, rendant les rÃ©sultats difficiles Ã  comparer et Ã  interprÃ©ter.
    *   **RÃ©solution :** L'implÃ©mentation a Ã©tÃ© rÃ©alisÃ©e sur l'ensemble de la pile. **1. Backend :** La colonne `llm_context_window` a Ã©tÃ© ajoutÃ©e Ã  la table `llm_evaluation_runs` via un modÃ¨le (`sql_models.py`) et une migration Alembic. Les schÃ©mas Pydantic (`settings_schema.py`) ont Ã©tÃ© mis Ã  jour pour recevoir et retourner cette donnÃ©e, et la fonction CRUD (`crud_settings.py`) a Ã©tÃ© adaptÃ©e pour la sauvegarder. **2. Frontend :** L'appel API dans `api.js` a Ã©tÃ© modifiÃ© pour inclure la fenÃªtre de contexte. Le gestionnaire d'Ã©vÃ©nements dans `events.js` a Ã©tÃ© corrigÃ© pour lire la valeur du champ de contexte et la passer Ã  l'API. Enfin, la fonction de rendu dans `ui.js` a Ã©tÃ© mise Ã  jour pour afficher les nouvelles colonnes "Model Name" et "Context" dans le tableau des rÃ©sultats.
    *   **Statut :** IMPLÃ‰MENTÃ‰.

*   **Visualisation des RÃ©sultats d'Ã‰valuation des ModÃ¨les LLM**
    *   **Analyse :** La fonctionnalitÃ© d'Ã©valuation des LLM a Ã©tÃ© implÃ©mentÃ©e, mais il n'existait aucun moyen de visualiser l'historique des rÃ©sultats, rendant la fonctionnalitÃ© incomplÃ¨te.
    *   **RÃ©solution :** L'historique des Ã©valuations est maintenant consultable directement depuis l'interface. **1. Backend :** Un nouveau schÃ©ma Pydantic (`LLMEvaluationRunResult`) a Ã©tÃ© crÃ©Ã© dans `app/schemas/settings_schema.py`. Une fonction CRUD `get_llm_evaluation_runs_by_category` a Ã©tÃ© ajoutÃ©e Ã  `app/database/crud_settings.py` pour rÃ©cupÃ©rer les donnÃ©es. Un nouvel endpoint `GET /api/settings/llm/evaluations/{llm_category}` a Ã©tÃ© implÃ©mentÃ© dans `app/api/settings_api.py` pour exposer ces donnÃ©es. **2. Frontend :** Une fonction d'appel `fetchLLMEvaluationResults` a Ã©tÃ© ajoutÃ©e Ã  `frontend/src/api.js`. Dans `frontend/src/ui.js`, la logique d'affichage a Ã©tÃ© crÃ©Ã©e via une nouvelle fonction `renderEvaluationResults`. Un bouton "View Results" a Ã©tÃ© ajoutÃ© aux blocs de configuration LLM, avec un gestionnaire d'Ã©vÃ©nements qui dÃ©clenche l'appel API et affiche les rÃ©sultats dans un tableau, avec un comportement de bascule (afficher/masquer).
    *   **Statut :** IMPLÃ‰MENTÃ‰.

*   **ImplÃ©mentation de l'Ã‰valuation des ModÃ¨les LLM (Backend & Frontend)**
    *   **Analyse :** Un besoin a Ã©tÃ© identifiÃ© pour tester objectivement la fiabilitÃ© et la performance des modÃ¨les LLM locaux directement depuis l'interface GroBot. L'objectif Ã©tait de simuler une charge de travail rÃ©aliste en faisant varier la taille du contexte et la fenÃªtre de contexte maximale allouÃ©e.
    *   **RÃ©solution :** La fonctionnalitÃ© a Ã©tÃ© implÃ©mentÃ©e de bout en bout. **1. Correctif PrÃ©alable :** Un bug empÃªchant la prise en compte du paramÃ¨tre `context_window` a Ã©tÃ© corrigÃ© dans `app/core/llm_manager.py`. **2. Backend (Base de DonnÃ©es) :** Une nouvelle table `llm_evaluation_runs` a Ã©tÃ© crÃ©Ã©e via un modÃ¨le dans `app/database/sql_models.py` et une migration Alembic pour stocker les rÃ©sultats. **3. Backend (API & Worker) :** Un nouvel endpoint `POST /api/settings/llm/evaluate` a Ã©tÃ© crÃ©Ã© dans `app/api/settings_api.py` pour lancer les Ã©valuations. Il utilise de nouveaux schÃ©mas Pydantic (`app/schemas/settings_schema.py`) et une fonction CRUD (`app/database/crud_settings.py`) pour crÃ©er une tÃ¢che en base de donnÃ©es avant de la dÃ©lÃ©guer Ã  Celery. Une nouvelle tÃ¢che `run_llm_evaluation` a Ã©tÃ© ajoutÃ©e dans `app/worker/tasks.py`, contenant la logique de test (double boucle, gestion d'Ã©tat, sauvegarde des rÃ©sultats). **4. Frontend (Interface & Logique) :** Un bouton "Evaluate" a Ã©tÃ© ajoutÃ© aux blocs de configuration LLM dans `frontend/src/ui.js`. Une fonction `startLLMEvaluation` a Ã©tÃ© crÃ©Ã©e dans `frontend/src/api.js` pour appeler le nouvel endpoint. Enfin, la logique de gestion du clic a Ã©tÃ© implÃ©mentÃ©e dans `frontend/src/events.js` et connectÃ©e dans `frontend/src/main.js`.
    *   **Statut :** IMPLÃ‰MENTÃ‰.

### 7.3. Bugs RÃ©cemment RÃ©solus

*   **Ã‰chec de la Restitution des RÃ©sultats d'Outils en Langage Naturel (Images et PersonnalitÃ©)**
    *   **Analyse :** Les outils appelÃ©s en langage naturel, comme la gÃ©nÃ©ration d'images, Ã©chouaient Ã  restituer correctement leur rÃ©sultat. L'investigation a rÃ©vÃ©lÃ© que l'hypothÃ¨se initiale d'une dÃ©faillance du `Planner` Ã©tait incorrecte. La cause racine Ã©tait une **perte de donnÃ©es critiques** dans la fonction `_format_tool_results_for_prompt` (`app/core/agents/synthesizer.py`), qui ignorait tous les rÃ©sultats d'outils n'Ã©tant pas de type `text`. L'agent `Synthesizer`, ne recevant aucune URL d'image, Ã©tait alors forcÃ© d'halluciner une rÃ©ponse textuelle erronÃ©e.
    *   **RÃ©solution :** Une refonte architecturale de la phase de synthÃ¨se a Ã©tÃ© implÃ©mentÃ©e. **1. SpÃ©cialisation des Agents :** Le `Synthesizer` a Ã©tÃ© scindÃ© en deux agents spÃ©cialisÃ©s. Le `Synthesizer` conversationnel original est conservÃ© pour les interactions sans outils, tandis qu'un nouveau `ToolResultSynthesizer` a Ã©tÃ© crÃ©Ã© avec un prompt dÃ©diÃ© Ã  la restitution des rÃ©sultats. **2. Routage Backend :** Une fonction d'aiguillage `run_synthesis_phase` a Ã©tÃ© ajoutÃ©e Ã  `app/core/agent_orchestrator.py` et est appelÃ©e par l'API (`app/api/chat_api.py`). Elle sÃ©lectionne le synthÃ©tiseur appropriÃ© en fonction de la prÃ©sence de rÃ©sultats d'outils. **3. Correction de la Perte de DonnÃ©es :** La fonction `_format_tool_results_for_prompt` a Ã©tÃ© corrigÃ©e pour traiter correctement les rÃ©sultats de type `image`, en les transformant en une description textuelle claire pour le LLM. **4. Contrat Client :** Pour garantir la fiabilitÃ©, le `ToolResultSynthesizer` a Ã©tÃ© instruit de formater les URL d'images dans une balise technique non-ambiguÃ« (`[IMAGE_URL:...]`). **5. ImplÃ©mentation Client :** La fonction `_handle_streaming_response` dans `discord_bot_launcher/client/event_handler.py` a Ã©tÃ© modifiÃ©e pour dÃ©tecter cette balise dans le message final, extraire l'URL, tÃ©lÃ©charger l'image via la fonction existante `_download_and_prepare_file`, et l'attacher au message Discord final. **6. AmÃ©lioration de la PersonnalitÃ© :** Le prompt du `ToolResultSynthesizer` a Ã©tÃ© affinÃ© pour prioriser la personnalitÃ© du bot, produisant des rÃ©ponses plus naturelles tout en respectant le formatage technique de l'image.
    *   **Statut :** RÃ‰SOLU.

*   **Ã‰chec de l'ExÃ©cution des Outils via Langage Naturel (IncompatibilitÃ© de Protocole)**
    *   **Analyse :** Les outils lents (ex: `generate_image`) Ã©chouaient lorsqu'ils Ã©taient appelÃ©s en langage naturel. L'investigation a montrÃ© que l'orchestrateur (`agent_orchestrator.py`) effectuait un appel HTTP synchrone et attendait une rÃ©ponse directe. Cependant, le serveur d'outils rÃ©pondait correctement avec un message `stream/start` pour initier une connexion WebSocket, ce que l'orchestrateur ne savait pas gÃ©rer.
    *   **RÃ©solution :** La fonction d'exÃ©cution des outils dans `app/core/agent_orchestrator.py` a Ã©tÃ© rendue "consciente du streaming". Elle est maintenant capable de dÃ©tecter la rÃ©ponse `stream/start`, d'extraire l'URL WebSocket et d'utiliser une nouvelle fonction helper (`_handle_mcp_stream`) pour se connecter au stream et attendre le rÃ©sultat final. Le mÃ©canisme de keepalive (ping/pong) a Ã©tÃ© ajoutÃ© pour garantir la robustesse de la connexion sans imposer de limite de temps arbitraire.
    *   **Statut :** RÃ‰SOLU (remplacÃ© par un bug plus spÃ©cifique).

*   **Ã‰chec de l'ExÃ©cution des Workflows avec Outils Asynchrones (Streaming)**
    *   **Analyse :** Les workflows utilisant des outils asynchrones (ex: `generate_image`) Ã©chouaient systÃ©matiquement. L'investigation a rÃ©vÃ©lÃ© une incompatibilitÃ© de protocole dans la tÃ¢che Celery `execute_workflow`. Le worker effectuait un appel HTTP synchrone et attendait une rÃ©ponse directe, alors que le serveur d'outils (MCP) rÃ©pondait avec un message `stream/start` pour initier une connexion WebSocket, conformÃ©ment au standard pour les tÃ¢ches longues. La logique du worker interprÃ©tait cette rÃ©ponse de streaming valide comme une erreur, car elle ne contenait pas la clÃ© `"result"` attendue, provoquant un `ValueError`.
    *   **RÃ©solution :** Le bug a Ã©tÃ© corrigÃ© en rendant la tÃ¢che `execute_workflow` (`app/worker/tasks.py`) "consciente du streaming". La logique de gestion de la rÃ©ponse MCP a Ã©tÃ© entiÃ¨rement revue pour traiter trois cas distincts : une rÃ©ponse d'erreur, une rÃ©ponse synchrone contenant une clÃ© `"result"`, ou une rÃ©ponse de dÃ©marrage de streaming (`{"method": "stream/start"}`). Dans ce dernier cas, la tÃ¢che extrait maintenant l'URL WebSocket (`ws_url`) de la rÃ©ponse et utilise la fonction asynchrone existante `_handle_mcp_stream` pour se connecter au stream, attendre et rÃ©cupÃ©rer le rÃ©sultat final de l'outil. De plus, la mÃ©canique de nouvelle tentative automatique (`retry`) sur Ã©chec a Ã©tÃ© supprimÃ©e, car les erreurs de workflow sont gÃ©nÃ©ralement dÃ©terministes.
    *   **Statut :** RÃ‰SOLU.

*   **Non-lancement des Workflows (Manuels et Cron)**
    *   **Analyse :** Les workflows ne se lanÃ§aient pas du tout. Les logs du worker Celery montraient que la tÃ¢che `execute_workflow` se terminait avec succÃ¨s en 1ms, car son contenu avait Ã©tÃ© accidentellement supprimÃ©. De plus, la planification (cron) n'Ã©tait pas implÃ©mentÃ©e.
    *   **RÃ©solution :** Une sÃ©rie de correctifs a Ã©tÃ© appliquÃ©e. **1. RÃ©-implÃ©mentation :** La logique complÃ¨te de `execute_workflow` a Ã©tÃ© restaurÃ©e dans `app/worker/tasks.py`. **2. ImplÃ©mentation du Cron :** Une nouvelle tÃ¢che `schedule_cron_workflows` a Ã©tÃ© crÃ©Ã©e pour scanner et lancer les workflows planifiÃ©s, et le `beat_schedule` a Ã©tÃ© configurÃ© dans `app/worker/celery_app.py` pour l'exÃ©cuter toutes les minutes. **3. DÃ©pendances :** La librairie `croniter` a Ã©tÃ© ajoutÃ©e Ã  `requirements.txt`. **4. DÃ©bogage ItÃ©ratif :** Plusieurs `AttributeError` et `UnsupportedProtocol` ont Ã©tÃ© corrigÃ©s en reconstruisant correctement l'URL des serveurs MCP. Des erreurs de validation de type (string vs list) ont Ã©tÃ© corrigÃ©es en ajoutant une logique de transformation de donnÃ©es dans le worker pour les outils `generate_prompt` et `generate_image`.
    *   **Statut :** RÃ‰SOLU (remplacÃ© par un bug plus spÃ©cifique).

*   **Anonymat de l'Historique de Conversation**
    *   **Analyse :** Les nouveaux logs LLM ont rÃ©vÃ©lÃ© un bug critique : l'historique des conversations envoyÃ© au LLM anonymisait tous les participants sous le rÃ´le gÃ©nÃ©rique "user". Le LLM Ã©tait incapable de distinguer qui parlait, ce qui l'empÃªchait de suivre des conversations multi-utilisateurs et de rÃ©pondre de maniÃ¨re contextuelle.
    *   **RÃ©solution :** Une correction a Ã©tÃ© appliquÃ©e sur l'ensemble de la chaÃ®ne de donnÃ©es. **1. SchÃ©ma :** Le champ optionnel `name` a Ã©tÃ© ajoutÃ© au schÃ©ma `ChatMessage` dans `app/schemas/chat_schemas.py`. **2. Client Discord :** La fonction `_fetch_history` dans `discord_bot_launcher/client/event_handler.py` a Ã©tÃ© modifiÃ©e pour rÃ©cupÃ©rer et inclure le `display_name` de chaque auteur de message. **3. Logging :** La fonction `log_llm_interaction` dans `app/core/llm_manager.py` a Ã©tÃ© mise Ã  jour pour afficher ce nouveau nom, rendant les logs lisibles et confirmant le correctif.
    *   **Statut :** RÃ‰SOLU.

*   **FenÃªtre de Contexte non SauvegardÃ©e lors de l'Ã‰valuation LLM**
    *   **Analyse :** AprÃ¨s la mise en place de l'interface pour l'ajout de la fenÃªtre de contexte, il a Ã©tÃ© constatÃ© que la valeur n'Ã©tait pas enregistrÃ©e. La colonne "Context" dans les rÃ©sultats affichait systÃ©matiquement "N/A". L'investigation a montrÃ© que le gestionnaire d'Ã©vÃ©nements JavaScript ne lisait pas la valeur de ce nouveau champ avant de lancer l'appel API.
    *   **RÃ©solution :** Le bug a Ã©tÃ© corrigÃ© dans la fonction `handleEvaluateLlm` du fichier `frontend/src/events.js`. La fonction a Ã©tÃ© modifiÃ©e pour lire l'attribut `data-context-field-id` du bouton, rÃ©cupÃ©rer la valeur de l'input correspondant et l'inclure dans la charge utile de la requÃªte envoyÃ©e Ã  l'API.
    *   **Statut :** RÃ‰SOLU.

*   **Ã‰chec de l'Ã‰valuation LLM et Cascade d'Erreurs AssociÃ©es**
    *   **Analyse :** Le symptÃ´me initial Ã©tait une erreur 404 "Not Found" lors du clic sur le bouton "Evaluate". L'enquÃªte a rÃ©vÃ©lÃ© une cascade d'erreurs Ã  plusieurs niveaux. La cause de la 404 Ã©tait que l'endpoint `/api/settings/llm/evaluate` Ã©tait complÃ¨tement manquant dans `app/api/settings_api.py`. AprÃ¨s sa rÃ©intÃ©gration, une `TypeError` a Ã©tÃ© dÃ©clenchÃ©e car l'API appelait la tÃ¢che Celery avec des arguments incorrects. Une fois ce problÃ¨me corrigÃ©, une `AttributeError` est apparue dans le worker car il tentait d'importer un modÃ¨le SQLAlchemy depuis le mauvais module. Le dernier obstacle Ã©tait une `ConnectionError`, car le conteneur du worker ne parvenait pas Ã  joindre le serveur Ollama. La cause en Ã©tait une configuration rÃ©seau manquante (`extra_hosts`) pour le service `worker` dans `docker-compose.yml`. ParallÃ¨lement, un bug de rÃ©gression a Ã©tÃ© dÃ©couvert : le bouton "Save Changes" des paramÃ¨tres globaux Ã©tait inopÃ©rant Ã  cause d'une `TypeError` JavaScript, due Ã  une incohÃ©rence entre les noms de champs gÃ©nÃ©rÃ©s dans `ui.js` et ceux lus dans `events.js`.
    *   **RÃ©solution :** Une sÃ©rie de correctifs a Ã©tÃ© appliquÃ©e sur l'ensemble de la pile. **1. API (`app/api/settings_api.py`) :** L'endpoint manquant a Ã©tÃ© rÃ©implÃ©mentÃ© et l'appel Ã  la tÃ¢che Celery a Ã©tÃ© corrigÃ© pour utiliser un dictionnaire unique, correspondant Ã  la signature attendue. **2. Worker (`app/worker/tasks.py`) :** L'importation du modÃ¨le `LLMEvaluationRun` a Ã©tÃ© corrigÃ©e pour pointer vers `app/database/sql_models.py`. **3. Frontend (`frontend/src/ui.js`) :** Les noms de catÃ©gories LLM ('tool', 'output') dans la fonction de rendu du formulaire ont Ã©tÃ© corrigÃ©s pour correspondre Ã  ceux attendus par le gestionnaire d'Ã©vÃ©nements, rÃ©parant ainsi le bouton de sauvegarde. **4. Orchestration (`docker-compose.yml`) :** La directive `extra_hosts` a Ã©tÃ© ajoutÃ©e aux services `worker` et `celery-beat` pour leur permettre de rÃ©soudre `host.docker.internal` et de se connecter au serveur Ollama, rÃ©solvant ainsi l'erreur de connexion finale.
    *   **Statut :** RÃ‰SOLU.

### 7.4. Points d'AmÃ©lioration Potentiels (Code/Architecture)

*   **Standardiser les Sorties d'Outils avec `outputSchema` :** Pour rÃ©soudre le bug d'exÃ©cution des workflows et amÃ©liorer radicalement l'UX de l'Ã©diteur, il est nÃ©cessaire d'Ã©tendre la dÃ©finition des outils MCP pour inclure un `outputSchema`. Cela permettra Ã  l'application de connaÃ®tre de maniÃ¨re dÃ©terministe la structure des donnÃ©es retournÃ©es par un outil, fiabilisant la liaison des donnÃ©es et permettant une interface utilisateur intuitive.

*   **Backend Implementation for Categorized LLM Configuration (`app/database/sql_models.py`, `app/schemas/*`, `app/api/*`)**
    *   **Description :** Le frontend a Ã©tÃ© mis Ã  jour pour permettre la configuration de modÃ¨les LLM par catÃ©gorie (DÃ©cisionnel, Outils, Output). Le backend doit maintenant Ãªtre adaptÃ© pour supporter cette nouvelle structure (migration de base de donnÃ©es, mise Ã  jour des schÃ©mas Pydantic et des endpoints, refactorisation de l'orchestrateur).
    *   **Impact :** La nouvelle configuration LLM n'est pas pleinement fonctionnelle tant que le backend n'est pas mis Ã  jour.

*   **AmÃ©liorer la Gestion de l'IdentitÃ© Utilisateur via un SystÃ¨me de Profils**
    *   **ProblÃ©matique :** L'implÃ©mentation actuelle envoie le `display_name` de l'utilisateur dans le prompt du LLM. C'est optimal pour la comprÃ©hension du modÃ¨le en langage naturel, mais cette donnÃ©e est volatile. Si un utilisateur change de pseudo, le bot perd le lien avec l'historique de ses connaissances sur cette personne, ce qui fragilise sa mÃ©moire Ã  long terme.
    *   **Solution ProposÃ©e :**
        *   Ancrer l'identitÃ© de chaque utilisateur Ã  son **ID Discord**, qui est unique et immuable.
        *   CrÃ©er une nouvelle table en base de donnÃ©es (ex: `user_profiles`) avec l'ID Discord comme clÃ© primaire.
        *   Cette table stockera des informations enrichies : le pseudo actuel (`current_display_name`), une liste des anciens pseudos connus (`known_aliases`), et une liste de surnoms (`nicknames`).
        *   Mettre en place une logique qui, Ã  chaque interaction, compare le pseudo actuel de l'utilisateur avec celui stockÃ©. En cas de diffÃ©rence, le systÃ¨me met Ã  jour le pseudo actuel et archive l'ancien dans la liste des alias.
    *   **Impact et BÃ©nÃ©fices :**
        *   **FiabilitÃ© de la MÃ©moire :** Le bot reconnaÃ®tra les utilisateurs de maniÃ¨re permanente, mÃªme s'ils changent de pseudo.
        *   **Contexte Enrichi :** Ouvre la possibilitÃ© d'interactions plus personnelles et contextuelles (ex: "Je vois que tu as changÃ© de nom, je te connaissais en tant que 'AncienPseudo'").
        *   **Fondation Solide :** CrÃ©e la base nÃ©cessaire pour implÃ©menter de futures fonctionnalitÃ©s liÃ©es aux prÃ©fÃ©rences et au profil de chaque utilisateur.

---

### 7.5. Plan d'Action pour la Prochaine Session

*   **TÃ¢che Prioritaire : RÃ©soudre le timeout de la commande `/prompt_generator`.**
    *   **Description :** Maintenant que la gestion des permissions par salon est implÃ©mentÃ©e et stable, la prochaine prioritÃ© est de reprendre l'investigation du bug de timeout intermittent sur les commandes slash. Cette tÃ¢che Ã©tait la prioritÃ© initiale avant la demande de gestion des permissions. L'investigation se poursuivra en se basant sur le plan d'action dÃ©fini (instrumentation et logging de performance).

---

## 8. ANNEXE : Anciennes Architectures d'Agent (ObsolÃ¨tes)

> **ATTENTION :** Cette section dÃ©crit les anciennes architectures qui ne sont plus en production. Elle est conservÃ©e Ã  titre de rÃ©fÃ©rence historique uniquement.

### 8.1. Architecture "ChaÃ®ne de Montage" Asynchrone (Session 96-121)

Cette architecture utilisait une chaÃ®ne de 4 LLM (Gardien, RÃ©partiteur, SynthÃ©tiseur, Archiviste) principalement orchestrÃ©e par le client `bot_process.py`. Le client gÃ©rait la dÃ©cision d'utiliser des outils, leur exÃ©cution (interne ou via proxy), et l'envoi des rÃ©sultats au SynthÃ©tiseur. Elle a Ã©tÃ© remplacÃ©e car la logique de dÃ©cision Ã©tait trop monolithique (un seul "RÃ©partiteur") et la gestion de la boucle d'outils par le client Ã©tait trop complexe.

### 8.2. Architecture Monolithique (PrÃ©-Session 96)

Cette architecture initiale reposait sur un unique appel LLM avec une liste d'outils au format `ollama-python`. Le client `bot_process.py` Ã©tait responsable de la gestion complÃ¨te de la boucle "appel LLM -> dÃ©tection d'appel d'outil -> exÃ©cution de l'outil -> second appel LLM avec le rÃ©sultat". Elle a Ã©tÃ© abandonnÃ©e en raison de sa faible fiabilitÃ© pour les tÃ¢ches complexes et du manque de contrÃ´le sur le raisonnement du LLM.