#### Date de derni√®re mise √† jour : 2025-10-11
    #### Ce fichier sert de r√©f√©rence unique et doit √™tre fourni en int√©gralit√© au d√©but de chaque session.
    
    ---
    ### AXIOMES FONDAMENTAUX DE LA SESSION ###
    ---
    
    #### **AXIOME 1 : COMPORTEMENTAL (L'Esprit de Collaboration)**
    
    *   **Posture d'Expert** : J'agis en tant qu'expert en d√©veloppement logiciel, m√©ticuleux et proactif. J'anticipe les erreurs potentielles et je sugg√®re des points de v√©rification pertinents apr√®s chaque modification.
    *   **Principe de Moindre Intervention** : Je ne modifie que ce qui est strictement n√©cessaire pour r√©pondre √† la demande. Je n'introduis aucune modification (ex: refactoring, optimisation) non sollicit√©e.
    *   **Partenariat Actif** : Je me positionne comme un partenaire de d√©veloppement qui analyse et propose, et non comme un simple ex√©cutant.
    *   **Gestion des Ambigu√Øt√©s** : Si une demande est ambigu√´ ou si des informations n√©cessaires √† sa bonne ex√©cution sont manquantes, je demanderai des clarifications avant de proposer une solution.
    
    #### **AXIOME 2 : ANALYSE ET S√âCURIT√â (Aucune Action Aveugle)**
    
    *   **Connaissance de l'√âtat Actuel** : Avant TOUTE modification de fichier, si je ne dispose pas de son contenu int√©gral et √† jour dans notre session, je dois imp√©rativement vous le demander. Une fois le contenu d'un fichier re√ßu, je consid√©rerai qu'il est √† jour et je ne le redemanderai pas, √† moins d'une notification explicite de votre part concernant une modification externe.
    *   **Analyse Pr√©alable Obligatoire** : Je ne proposerai jamais de commande de modification de code (ex: `sed`) sans avoir analys√© le contenu du fichier concern√© au pr√©alable dans la session en cours.
    *   **V√©rification Proactive des D√©pendances** : Ma base de connaissances s'arr√™te d√©but 2023. Par cons√©quent, avant d'int√©grer ou d'utiliser un nouvel outil, une nouvelle librairie ou un nouveau package, je dois syst√©matiquement effectuer une recherche. Je r√©sumerai les points cl√©s (version stable, breaking changes, nouvelles pratiques d'utilisation) dans le fichier `project_context.md`.
    *   **Protection des Donn√©es** : Je ne proposerai jamais d'action destructive (ex: `rm`, `DROP TABLE`) sur des donn√©es en environnement de d√©veloppement sans proposer une alternative de contournement (ex: renommage, sauvegarde).
    
    #### **AXIOME 3 : RESTITUTION DU CODE (Clart√© et Fiabilit√©)**
    
    *   **M√©thode 1 - Modification Atomique par `sed`** :
        *   **Usage** : Uniquement pour une modification simple, cibl√©e sur une seule ligne (modification de contenu, ajout ou suppression), et sans aucun risque d'erreur de syntaxe ou de contexte.
        *   **Format** : La commande `sed` doit √™tre fournie sur une seule ligne pour Git Bash, avec l'argument principal encapsul√© dans des guillemets simples (`'`). Le nouveau contenu du fichier ne sera pas affich√©.
        *   **Exclusivit√©** : Aucun autre outil en ligne de commande (`awk`, `patch`, `tee`, etc.) ne sera utilis√© pour la modification de fichiers.
    *   **M√©thode 2 - Fichier Complet (Par D√©faut)** :
        *   **Usage** : C'est la m√©thode par d√©faut. Elle est obligatoire si une commande `sed` est trop complexe, risqu√©e, ou si les modifications sont substantielles.
        *   **Format** : Je fournis le contenu int√©gral et mis √† jour du fichier.
    *   **Formatage des Blocs de Restitution** :
        *   **Fichiers Markdown (`.md`)** : J'utiliserai un bloc de code markdown (```md) non indent√©. Le contenu int√©gral du fichier sera syst√©matiquement indent√© de quatre espaces √† l'int√©rieur de ce bloc.
        *   **Autres Fichiers (Code, Config, etc.)** : J'utiliserai un bloc de code standard (```langue). Les balises d'ouverture et de fermeture ne seront jamais indent√©es, mais le code √† l'int√©rieur le sera syst√©matiquement de quatre espaces.
    
    #### **AXIOME 4 : WORKFLOW (Un Pas Apr√®s l'Autre)**
    
    1.  **Validation Explicite** : Apr√®s chaque proposition de modification (que ce soit par `sed` ou par fichier complet), je marque une pause. J'attends votre accord explicite ("OK", "Appliqu√©", "Valid√©", etc.) avant de passer √† un autre fichier ou √† une autre t√¢che.
    2.  **Documentation Continue des D√©pendances** : Si la version d'une d√©pendance s'av√®re plus r√©cente que ma base de connaissances, je consigne son num√©ro de version et les notes d'utilisation pertinentes dans le fichier `project_context.md`.
    3.  **Documentation de Fin de Fonctionnalit√©** : √Ä la fin du d√©veloppement d'une fonctionnalit√© majeure et apr√®s votre validation finale, je proposerai de mani√®re proactive la mise √† jour des fichiers de suivi du projet, notamment `project_context.md` et `features.md`.
    
    #### **AXIOME 5 : LINGUISTIQUE (Bilinguisme Strict)**
    
    *   **Nos Interactions** : Toutes nos discussions, mes explications et mes questions se d√©roulent exclusivement en **fran√ßais**.
    *   **Le Produit Final** : Absolument tout le livrable (code, commentaires, docstrings, noms de variables, logs, textes d'interface, etc.) est r√©dig√© exclusivement en **anglais**.
    
    ---
    ### FIN DES AXIOMES FONDAMENTAUX ###
    ---
    
    
    ---
    ### 1. Vision et Objectifs du Projet
    
    Le projet "GroBot" vise √† cr√©er une plateforme d'h√©bergement et de gestion **pour une flotte de bots Discord enti√®rement ind√©pendants**. Il ne s'agit pas d'un seul bot multi-personnalit√©s, mais d'une infrastructure capable de faire tourner de multiples processus de bots en parall√®le.
    
    L'objectif principal est une **administrabilit√© dynamique** via une **interface web moderne de type SPA (Single Page Application)**, permettant l'ajout, la configuration ou la d√©sactivation d'un bot √† chaud, **sans n√©cessiter le red√©marrage des bots d√©j√† en cours d'ex√©cution**.
    
    ---
    
    ## 2. Principes d'Architecture Fondamentaux
    
    1.  **Architecture d'Application Combin√©e :** Pour simplifier le d√©ploiement et √©liminer les probl√®mes de CORS, le Frontend et le Backend sont servis par un **unique service conteneuris√©**. Nginx agit comme reverse proxy : il sert les fichiers statiques du frontend et redirige les requ√™tes API vers le processus FastAPI tournant dans le m√™me conteneur.
    2.  **Configuration Centralis√©e en Base de Donn√©es :** Toute la configuration sp√©cifique √† un bot est stock√©e **uniquement** dans PostgreSQL. Le fichier `.env` est r√©serv√© √† la configuration de la plateforme.
    3.  **Isolation par Processus :** Chaque bot actif tourne dans son propre processus syst√®me, g√©r√© par le service `discord-bot-launcher`.
    4.  **Isolation des Donn√©es (M√©moire) :** La m√©moire √† long terme (LTM) est stock√©e dans ChromaDB au sein d'une **collection d√©di√©e par bot**.
    5.  **Communication Conteneur-H√¥te :** L'URL `http://host.docker.internal:[port]` est la valeur standard pour qu'un conteneur acc√®de √† un service sur l'h√¥te. Les services communiquent entre eux via leur nom de service (ex: `http://app:8000`, `http://ollama:11434`).
    6.  **Gestion du Sch√©ma de Base de Donn√©es :** Alembic est la **seule autorit√©** pour la gestion du sch√©ma de la base de donn√©es. L'appel `Base.metadata.create_all()` n'est pas utilis√© en production pour √©viter tout conflit. Pour les relations "plusieurs-√†-plusieurs" avec des donn√©es additionnelles (ex: la configuration d'un outil pour un bot), le patron de conception **Association Object** de SQLAlchemy est utilis√©.
    7.  **Structure des Chemins dans le Conteneur `app` :** En raison de la configuration Docker, le r√©pertoire `app` du projet est copi√© dans le r√©pertoire `/app` du conteneur. Par cons√©quent, le chemin d'acc√®s absolu pour les fichiers du projet (comme `alembic.ini`) √† l'int√©rieur du conteneur est syst√©matiquement `/app/app/...`. Cette convention doit √™tre respect√©e pour toutes les commandes `docker-compose exec`.
    8.  **Architecture de Prompt Hybride :** Le prompt syst√®me final envoy√© au LLM est assembl√© dynamiquement par la logique m√©tier. Il combine des **directives fondamentales non-modifiables** (cod√©es en dur pour tous les bots) avec le **contexte d'ex√©cution dynamique** (serveur/salon Discord, fichiers joints, m√©moire LTM) et la **personnalit√© sp√©cifique au bot** (stock√©e en base de donn√©es).
    9.  **Agentique et Ex√©cution des Outils C√¥t√© Client :** La boucle de l'agent (LLM -> appel d'outil -> LLM) est g√©r√©e par le client, c'est-√†-dire `bot_process.py`, et non par le backend. Cette approche garantit la **s√©curit√© maximale** (le token Discord ne quitte jamais son processus) et permet l'impl√©mentation d'**outils internes** qui interagissent directement avec l'objet client `discord.py`. Les outils externes (MCP) sont appel√©s via un **endpoint API proxy d√©di√© (`/api/tools/call`)** qui centralise la logique de communication.
    10. **M√©moire Utilisateur √† Deux Composants :** La connaissance persistante du bot sur les utilisateurs est divis√©e en deux types de donn√©es distincts : les **Profils Utilisateurs** (contenant des directives comportementales modifiables par un administrateur) et les **Notes Utilisateurs** (contenant des faits textuels avec un score de fiabilit√©, que le bot peut cr√©er et lire lui-m√™me via ses outils).
    11. **Architecture d'Agent Sp√©cialis√© ("Cha√Æne de Montage") :** Pour fiabiliser l'utilisation des outils, le traitement d'un message est d√©compos√© en une s√©rie d'appels LLM sp√©cialis√©s. Chaque LLM a un r√¥le unique et d√©fini (Gardien, Planificateur, Synth√©tiseur, etc.). L'orchestration de cette cha√Æne est g√©r√©e par le backend.
    12. **Sp√©cialisation des Mod√®les LLM par Cat√©gorie de T√¢che :** Pour optimiser les performances et les co√ªts, la configuration LLM est segment√©e en trois cat√©gories fonctionnelles, chacune pouvant √™tre assign√©e √† un serveur, un mod√®le et une fen√™tre de contexte sp√©cifiques. Ces cat√©gories sont :
        *   **D√©cisionnel :** Mod√®les rapides pour des t√¢ches de classification ou de filtrage (ex: `Gatekeeper`).
        *   **Outils :** Mod√®les fiables avec un bon raisonnement logique pour la g√©n√©ration de JSON et l'appel d'outils (ex: `Parameter Extractor`).
        *   **Output Client :** Mod√®les puissants et cr√©atifs pour la g√©n√©ration des r√©ponses finales √† l'utilisateur (ex: `Synthesizer`).
    
    ---
    
    ## 3. Architecture et Technologies
    
    ### 3.1. Technologies Principales
    *   **Orchestration :** Docker, Docker Compose
    *   **Backend API :** FastAPI
    *   **Serveur Applicatif :** Nginx (agissant comme serveur web statique et reverse proxy) et Uvicorn (pour l'API FastAPI).
    *   **Gestion des processus Bots :** Python 3.11+, `subprocess`
    *   **Base de Donn√©es Relationnelle (Gestion) :** PostgreSQL (via SQLAlchemy)
    *   **Migration de Base de Donn√©es :** Alembic (pour les mises √† jour de sch√©ma non-destructives)
    *   **Base de Donn√©es Vectorielle (M√©moire LTM Isol√©e) :** ChromaDB
    *   **Interaction LLM :** `requests`, `httpx`, `ollama-python`
    *   **Client Discord :** `discord.py`
    *   **T√¢ches Asynchrones :** Celery, Redis
    
    ### 3.2. Arborescence Compl√®te du Projet et R√¥le des Fichiers
    
    ```
    üìÅ GroBot/
      ‚îú‚îÄ üìÑ .dockerignore                 # Ignore les fichiers non n√©cessaires lors de la construction de l'image Docker.
      ‚îú‚îÄ üìÑ .env.example                  # Fichier d'exemple pour les variables d'environnement.
      ‚îú‚îÄ üìÑ docker-compose.yml            # D√©finit et orchestre tous les services de l'application.
      ‚îú‚îÄ üìÑ Dockerfile                    # Recette multi-stage pour l'image 'app' (API+Frontend).
      ‚îú‚îÄ üìÑ features.md                   # Suivi de haut niveau des fonctionnalit√©s.
      ‚îú‚îÄ üìÑ project_context.md            # Ce fichier, source de v√©rit√© du projet.
      ‚îú‚îÄ üìÑ requirements.txt              # D√©pendances Python pour le service 'app'.
      ‚îÇ
      ‚îú‚îÄ üìÅ app/                           # C≈ìur du Backend : API et logique m√©tier.
      ‚îÇ  ‚îú‚îÄ üìÑ __init__.py                 # Marque le dossier comme un package Python.
      ‚îÇ  ‚îú‚îÄ üìÑ alembic.ini                 # Fichier de configuration pour Alembic.
      ‚îÇ  ‚îú‚îÄ üìÑ config.py                   # Charge les variables d'environnement via Pydantic.
      ‚îÇ  ‚îú‚îÄ üìÑ main.py                     # Point d'entr√©e de l'API FastAPI, g√®re le cycle de vie et les routeurs.
      ‚îÇ  ‚îÇ
      ‚îÇ  ‚îú‚îÄ üìÅ alembic/                    # Dossier pour la gestion des migrations de base de donn√©es.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ README                    # Instructions pour Alembic.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ env.py                    # Script de configuration d'environnement pour Alembic.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ script.py.mako            # Template pour les nouveaux scripts de migration.
      ‚îÇ  ‚îÇ  ‚îî‚îÄ üìÅ versions/               # Contient tous les scripts de migration g√©n√©r√©s.
      ‚îÇ  ‚îÇ     ‚îî‚îÄ ... (fichiers de migration auto-g√©n√©r√©s)
      ‚îÇ  ‚îÇ
      ‚îÇ  ‚îú‚îÄ üìÅ api/                        # Contient les routeurs FastAPI (endpoints).
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ __init__.py               # Marque le dossier comme un package Python.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ bots_api.py               # API pour la gestion des bots (CRUD).
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ bots_api.py.bak           # Fichier de sauvegarde, non utilis√©.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ chat_api.py               # API pour l'orchestration des agents et le chat.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ files_api.py              # API pour la gestion des fichiers.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ llm_api.py                # API pour l'interaction avec les LLMs (ex: lister les mod√®les).
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ mcp_api.py                # API pour la gestion des serveurs MCP.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ settings_api.py           # API pour les param√®tres globaux.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ tools_api.py              # API proxy pour l'ex√©cution des outils externes (MCP).
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ user_profiles_api.py      # API pour la gestion des profils et notes utilisateurs.
      ‚îÇ  ‚îÇ  ‚îî‚îÄ üìÑ workflows_api.py          # API pour la gestion des workflows (CRUD et ex√©cution).
      ‚îÇ  ‚îÇ
      ‚îÇ  ‚îú‚îÄ üìÅ core/                       # Logique m√©tier principale de l'application.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ __init__.py               # Marque le dossier comme un package Python.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ agent_logic.py.old        # Fichier de sauvegarde, non utilis√©.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ agent_orchestrator.py     # Orchestre la cha√Æne d'appels aux agents sp√©cialis√©s.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ llm_manager.py            # G√®re les instances de clients LLM et les interactions.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ websocket_manager.py      # G√®re les connexions WebSocket persistantes avec les clients bot.
      ‚îÇ  ‚îÇ  ‚îî‚îÄ üìÅ agents/                 # Contient la logique pour chaque agent LLM sp√©cialis√©.
      ‚îÇ  ‚îÇ     ‚îú‚îÄ üìÑ __init__.py           # Marque le dossier comme un package Python.
      ‚îÇ  ‚îÇ     ‚îú‚îÄ üìÑ acknowledger.py       # Agent pour g√©n√©rer les messages d'attente.
      ‚îÇ  ‚îÇ     ‚îú‚îÄ üìÑ archivist.py          # Agent pour archiver les informations en m√©moire.
      ‚îÇ  ‚îÇ     ‚îú‚îÄ üìÑ clarifier.py          # Agent pour demander des informations manquantes.
      ‚îÇ  ‚îÇ     ‚îú‚îÄ üìÑ gatekeeper.py         # Agent pour d√©cider si le bot doit r√©pondre.
      ‚îÇ  ‚îÇ     ‚îú‚îÄ üìÑ parameter_extractor.py# Agent pour extraire les param√®tres des outils.
      ‚îÇ  ‚îÇ     ‚îú‚îÄ üìÑ planner.py            # Agent pour cr√©er le plan d'ex√©cution des outils.
      ‚îÇ  ‚îÇ     ‚îú‚îÄ üìÑ prompts.py            # Centralise tous les prompts syst√®me des agents.
      ‚îÇ  ‚îÇ     ‚îú‚îÄ üìÑ synthesizer.py        # Agent pour formuler la r√©ponse finale.
      ‚îÇ  ‚îÇ     ‚îî‚îÄ üìÑ tool_identifier.py    # Agent pour identifier les outils n√©cessaires.
      ‚îÇ  ‚îÇ
      ‚îÇ  ‚îú‚îÄ üìÅ database/                   # Module pour l'acc√®s aux bases de donn√©es.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ __init__.py               # Marque le dossier comme un package Python.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ base.py                   # D√©finit la base d√©clarative SQLAlchemy.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ chroma_manager.py         # G√®re les interactions avec ChromaDB (m√©moire vectorielle).
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ crud_bots.py              # Fonctions CRUD pour les bots.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ crud_files.py             # Fonctions CRUD pour les fichiers.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ crud_mcp.py               # Fonctions CRUD pour les serveurs MCP.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ crud_settings.py          # Fonctions CRUD pour les param√®tres globaux.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ crud_user_notes.py        # Fonctions CRUD pour les notes sur les utilisateurs.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ crud_user_profiles.py     # Fonctions CRUD pour les profils utilisateurs.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ crud_workflows.py         # Fonctions CRUD pour les workflows.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ redis_session.py          # G√®re la connexion au client Redis.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ sql_models.py             # D√©finit les mod√®les de table SQLAlchemy.
      ‚îÇ  ‚îÇ  ‚îî‚îÄ üìÑ sql_session.py            # G√®re la session de base de donn√©es SQL.
      ‚îÇ  ‚îÇ
      ‚îÇ  ‚îú‚îÄ üìÅ schemas/                    # Contient les sch√©mas Pydantic pour la validation des donn√©es API.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ __init__.py               # Marque le dossier comme un package Python.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ bot_schemas.py            # Sch√©mas Pydantic pour les bots.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ chat_schemas.py           # Sch√©mas Pydantic pour le chat et les agents.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ file_schemas.py           # Sch√©mas Pydantic pour les fichiers.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ mcp_schemas.py            # Sch√©mas Pydantic pour les serveurs MCP.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ settings_schema.py        # Sch√©mas Pydantic pour les param√®tres.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ user_note_schemas.py      # Sch√©mas Pydantic pour les notes utilisateurs.
      ‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑ user_profile_schemas.py   # Sch√©mas Pydantic pour les profils utilisateurs.
      ‚îÇ  ‚îÇ  ‚îî‚îÄ üìÑ workflow_schemas.py       # Sch√©mas Pydantic pour les workflows.
      ‚îÇ  ‚îÇ
      ‚îÇ  ‚îî‚îÄ üìÅ worker/                     # Configuration pour les t√¢ches de fond (Celery).
      ‚îÇ     ‚îú‚îÄ üìÑ __init__.py               # Marque le dossier comme un package Python.
      ‚îÇ     ‚îú‚îÄ üìÑ celery_app.py             # D√©finit l'instance de l'application Celery.
      ‚îÇ     ‚îî‚îÄ üìÑ tasks.py                  # D√©finit les t√¢ches Celery (ex: archivage, ex√©cution de workflows).
      ‚îÇ
      ‚îú‚îÄ üìÅ chromadb_overriden/
      ‚îÇ  ‚îî‚îÄ üìÑ Dockerfile                  # Personnalise l'image ChromaDB (ex: ajout de 'curl').
      ‚îÇ
      ‚îú‚îÄ üìÅ discord_bot_launcher/         # Service isol√© qui g√®re les processus des bots Discord.
      ‚îÇ  ‚îú‚îÄ üìÑ bot_process.py              # Point d'entr√©e du client Discord, initialise les handlers.
      ‚îÇ  ‚îú‚îÄ üìÑ bot_process.py.old          # Fichier de sauvegarde, non utilis√©.
      ‚îÇ  ‚îú‚îÄ üìÑ Dockerfile                  # Image Docker pour le service launcher.
      ‚îÇ  ‚îú‚îÄ üìÑ launcher.py                 # Script qui surveille l'API et lance/arr√™te les bots.
      ‚îÇ  ‚îú‚îÄ üìÑ requirements.txt            # D√©pendances Python pour le service launcher.
      ‚îÇ  ‚îî‚îÄ üìÅ client/                     # Logique modulaire du client Discord.
      ‚îÇ     ‚îú‚îÄ üìÑ __init__.py               # Marque le dossier comme un package Python.
      ‚îÇ     ‚îú‚îÄ üìÑ api_client.py             # Centralise toutes les requ√™tes vers l'API backend.
      ‚îÇ     ‚îú‚îÄ üìÑ discord_ui.py             # Fonctions utilitaires pour l'UI de Discord (r√©actions, etc.).
      ‚îÇ     ‚îî‚îÄ üìÑ event_handler.py          # Contient la logique principale `on_message`.
      ‚îÇ
      ‚îú‚îÄ üìÅ frontend/                     # Application combin√©e (Nginx + SPA).
      ‚îÇ  ‚îú‚îÄ üìÑ entrypoint.sh               # Script de d√©marrage pour le conteneur 'app' (nginx + uvicorn).
      ‚îÇ  ‚îú‚îÄ üìÑ nginx.conf                  # Configuration Nginx (reverse proxy et fichiers statiques).
      ‚îÇ  ‚îî‚îÄ üìÅ src/                        # Code source JavaScript pour l'interface utilisateur.
      ‚îÇ     ‚îú‚îÄ üìÑ api.js                    # Fonctions utilitaires pour les appels API.
      ‚îÇ     ‚îú‚îÄ üìÑ events.js                 # Gestionnaires d'√©v√©nements (formulaires, WebSocket).
      ‚îÇ     ‚îú‚îÄ üìÑ index.html                # Structure HTML de l'application.
      ‚îÇ     ‚îú‚îÄ üìÑ main.js                   # Point d'entr√©e JavaScript, initialisation et routage.
      ‚îÇ     ‚îú‚îÄ üìÑ style.css                 # Styles CSS.
      ‚îÇ     ‚îú‚îÄ üìÑ ui.js                     # Fonctions pour manipuler le DOM et mettre √† jour l'UI.
      ‚îÇ     ‚îî‚îÄ üìÑ workflow_editor.js        # Module UI pour l'√©diteur de workflows.
      ‚îÇ
      ‚îî‚îÄ üìÅ grobot_tools/                 # Service MCP contenant les outils standards.
         ‚îú‚îÄ üìÑ Dockerfile                  # Dockerfile pour le service d'outils.
         ‚îú‚îÄ üìÑ requirements.txt            # D√©pendances Python pour les outils.
         ‚îú‚îÄ üìÑ supervisord.conf            # Configuration Supervisor pour lancer les outils.
         ‚îú‚îÄ üìÅ file_tools/                 # Outils de gestion de fichiers.
         ‚îÇ  ‚îî‚îÄ üìÑ server.py                 # Point d'entr√©e du serveur MCP pour les outils de fichiers.
         ‚îî‚îÄ üìÅ time_tool/                  # Outils li√©s au temps.
            ‚îî‚îÄ üìÑ server.py                 # Point d'entr√©e du serveur MCP pour l'outil de temps.
    ```
    
    ---
    
    ## 4. Vision de l'Interface Cible (Post-Refonte)
    
    *   **Disposition G√©n√©rale :** Une application √† deux colonnes principales.
        *   **Colonne de Gauche (Sidebar, redimensionnable) :**
            *   **Titre :** "GroBot".
            *   **Liste des Bots :** Affiche tous les bots configur√©s. Chaque √©l√©ment montre le nom du bot et son √©tat (en ligne/hors ligne).
            *   **Boutons d'Action Globale :**
                *   Un bouton pour "Add Bot".
                *   Un bouton "roue crant√©e" pour "Configuration Globale".
        *   **Colonne de Droite (Contenu Principal) :**
            *   **En-t√™te :** Affiche le nom du bot/de la vue actuellement s√©lectionn√©(e), et des contr√¥les (ex: boutons de th√®me).
            *   **Zone de Contenu :** Affiche la vue s√©lectionn√©e pour un bot via un syst√®me d'onglets. Les onglets principaux sont :
                *   **Test Chat :** Une interface pour interagir directement avec le bot.
                *   **Logs :** Un dashboard de logs en temps r√©el.
                *   **Settings :** Le formulaire de configuration du bot, incluant les nouveaux r√©glages LLM par cat√©gorie (serveur, mod√®le, contexte).
                *   **Files :** Le gestionnaire de fichiers du bot.
                *   **Memory :** Une vue de la m√©moire vectorielle du bot.
                *   **Knowledge Base :** Une interface pour g√©rer les connaissances du bot sur les utilisateurs. Cette vue affiche une barre de recherche et, par d√©faut, la liste des utilisateurs connus par ce bot. Un clic sur un utilisateur ou une recherche r√©ussie affiche la vue d√©taill√©e du profil et des notes de cet utilisateur.
                *   **Workflows :** Une vue pour g√©rer les automatisations. Affiche une grille de "cartes", chacune repr√©sentant un workflow avec des options pour l'ex√©cuter, le modifier ou le supprimer.
    
    ---
    
    ## 6. Documentation : Le Standard Model Context Protocol (MCP)
    
    *   **Date d'Adoption :** 2025-08-15
    *   **Source de V√©rit√© :** [D√©p√¥t GitHub Officiel](https://github.com/modelcontextprotocol/modelcontextprotocol) et [Documentation](https://modelcontextprotocol.info/docs/)
    
    Cette section annule et remplace toute impl√©mentation pr√©c√©dente d'outils. Le projet adopte le standard ouvert et officiel MCP pour l'int√©gration des outils.
    
    ### 6.1. Principes Fondamentaux
    
    1.  **Communication Standardis√©e :** Toutes les interactions entre un client (notre `bot_process`) et un serveur d'outils (ex: `mcp_time_tool`) **DOIVENT** utiliser le protocole **JSON-RPC 2.0**.
    2.  **M√©thodes RPC Sp√©cifi√©es :** Le standard d√©finit des noms de m√©thodes pr√©cis que les serveurs doivent impl√©menter et que les clients doivent appeler. Les deux m√©thodes fondamentales pour les outils sont `tools/list` et `tools/call`.
    3.  **D√©finition via JSON Schema :** La "signature" d'un outil (son nom, sa description, ses param√®tres et leurs types) est d√©crite de mani√®re structur√©e via une JSON Schema. C'est ce qui permet une d√©couverte v√©ritablement automatique et fiable.
    
    ### 6.2. M√©thodes RPC Standard
    
    #### 6.2.1. `tools/list`
    
    *   **R√¥le :** Permet √† client de d√©couvrir les outils disponibles sur un serveur.
    *   **Requ√™te du Client :**
        ```json
        {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "tools/list",
            "params": {}
        }
        ```
    *   **R√©ponse du Serveur :**
        ```json
        {
            "jsonrpc": "2.0",
            "id": 1,
            "result": {
                "tools": [
                    // ... liste des d√©finitions d'outils ...
                ]
            }
        }
        ```
    
    #### 6.2.2. `tools/call`
    
    *   **R√¥le :** Permet √† client d'ex√©cuter un outil sp√©cifique avec des arguments.
    *   **Requ√™te du Client :**
        ```json
        {
            "jsonrpc": "2.0",
            "id": 2,
            "method": "tools/call",
            "params": {
                "name": "tool_name_to_call",
                "arguments": {
                    "param1_name": "value1",
                    "param2_name": 123
                }
            }
        }
        ```
    *   **R√©ponse du Serveur :**
        ```json
        {
            "jsonrpc": "2.0",
            "id": 2,
            "result": {
                "content": [
                    {
                        "type": "text",
                        "text": "The result of the tool execution."
                    }
                ]
            }
        }
        ```
        
    ### 6.3. Format de D√©finition d'un Outil
    
    Chaque outil retourn√© par `tools/list` **DOIT** suivre le format JSON Schema suivant, avec la cl√© `inputSchema` pour les param√®tres.
    
    **Exemple pour `get_current_time` :**
    ```json
    {
        "name": "get_current_time",
        "title": "Get Current Time",
        "description": "Returns the current server date and time. Use this for any questions about the current time, date, or day of the week.",
        "inputSchema": {
            "type": "object",
            "properties": {}
        }
    }
    ```
    
    ### 6.4. Impl√©mentations MCP Connues
    
    Pour garantir l'interop√©rabilit√©, GroBot s'appuie sur des serveurs d'outils qui respectent le standard MCP. La documentation de r√©f√©rence pour ces serveurs est essentielle pour comprendre les outils disponibles.
    
    *   **MCP_GenImage:** Service avanc√© de g√©n√©ration d'images.
        *   *[Lien vers le project_context.md de MCP_GenImage √† ins√©rer ici]*
    
    ---
    
    ## 7. √âtat Actuel et Plan d'Action
    
    ### 7.1. Bugs Connus et R√©gression (Issues Actuellement Ouvertes)
    
    *   **Pr√©-remplissage Incomplet de l'√âditeur de Workflow en Mode √âdition (`frontend/src/workflow_editor.js`)**
        *   **Description :** Lors de l'√©dition d'un workflow existant (par exemple, un workflow avec 3 √©tapes), le modal de l'√©diteur s'ouvre mais la derni√®re √©tape appara√Æt vide, ses param√®tres n'√©tant pas charg√©s.
        *   **Hypoth√®se/Investigation :** Une premi√®re tentative de correction a √©t√© effectu√©e en supposant une "race condition" dans le rendu asynchrone des √©tapes. Le remplacement d'une boucle `forEach` par une boucle `for...of` n'a pas r√©solu le probl√®me. L'investigation doit se poursuivre pour identifier la cause de l'√©chec du rendu de la derni√®re √©tape.
        *   **Statut :** NON R√âSOLU.
    
    *   **Timeout de la commande `/prompt_generator` et √âchec de l'Autocompl√©tion des Styles (`app/api/tools_api.py`, `discord_bot_launcher/client/event_handler.py`)**
        *   **Description :** La commande `/prompt_generator` √©choue par intermittence avec une erreur "Cette interaction a √©chou√©" (timeout de 3 secondes de Discord). Simultan√©ment, la liste des styles pour l'autocompl√©tion est souvent vide. Le bug ne se produit que lorsque le cache des d√©finitions d'outils du backend est expir√©.
        *   **Hypoth√®se :** Il s'agit d'une "course au d√©lai". La d√©couverte des outils, qui interroge tous les serveurs MCP, prend parfois trop de temps, m√™me en local, et d√©passe les d√©lais stricts de Discord pour la r√©ponse √† une interaction.
        *   **Plan d'action :** L'investigation est en cours. La premi√®re √©tape convenue est d'appliquer une version instrument√©e de `app/api/tools_api.py` qui ajoute des logs de performance d√©taill√©s. Ces logs permettront de mesurer pr√©cis√©ment le temps pris par les appels r√©seau et de confirmer ou d'infirmer l'hypoth√®se de la latence avant d'appliquer un correctif.
        *   **Statut :** EN COURS D'INVESTIGATION.
    
    *   **Probl√®me d'Interface Utilisateur dans l'Onglet "Memory" (`frontend/src/ui.js`, `app/api/chat_api.py`)**
        *   **Description :** L'onglet "Memory" dans l'interface utilisateur ne fonctionne pas. Le code de `frontend/src/ui.js` contient une section comment√©e ou une r√©f√©rence √† `fetchBotMemory` qui ne semble pas √™tre correctement appel√©e ou rendue.
        *   **Impact :** L'utilisateur ne peut pas consulter la m√©moire conversationnelle du bot.
        *   **Statut :** NON R√âSOLU.
    
    *   **Outils non Fonctionnels dans l'Interface de Test (`frontend/src/ui.js`)**
        *   **Description :** Les outils (comme `generate_image` ou `describe_image`) ne fonctionnent pas lorsqu'ils sont appel√©s depuis l'interface de test chat dans le frontend. Le code dans `handleTestChatSubmit` ne semble pas g√©rer l'ex√©cution des outils directement.
        *   **Impact :** L'utilisateur ne peut pas tester les fonctionnalit√©s des outils via l'interface web.
        *   **Statut :** NON R√âSOLU.
    
    *   **Suppression de Bot Impossible (`frontend/src/ui.js`, `app/api/bots_api.py`)**
        *   **Description :** La fonctionnalit√© de suppression d'un bot n'est pas impl√©ment√©e dans l'interface utilisateur (pas de bouton ou de logique de gestion pour la suppression) ni dans l'API backend (`bots_api.py`). Bien que le `crud_bots.delete_bot` existe, il n'est pas appel√© par une route API.
        *   **Impact :** Les utilisateurs ne peuvent pas supprimer des bots via l'interface web.
        *   **Statut :** NON R√âSOLU.
    
    ### 7.2. Fonctionnalit√©s R√©cemment Impl√©ment√©es
    
    *   **Impl√©mentation du Logging des Interactions LLM**
        *   **Analyse :** Un besoin crucial de d√©bogage a √©t√© identifi√© : visualiser les prompts exacts envoy√©s aux LLM et les r√©ponses brutes re√ßues. Cela est essentiel pour comprendre le comportement des agents et corriger les probl√®mes de contexte.
        *   **R√©solution :** Un syst√®me de logging d√©di√© a √©t√© impl√©ment√©. **1. Infrastructure :** Un r√©pertoire `logs/` a √©t√© cr√©√© et mont√© via un volume dans `docker-compose.yml`. **2. Backend :** Une fonction de logging d√©di√©e (`log_llm_interaction`) a √©t√© ajout√©e dans `app/core/llm_manager.py`. Elle √©crit chaque interaction (prompt et r√©ponse) dans un fichier `logs/llm_interactions.md` dans un format Markdown lisible. Cette fonction est appel√©e depuis les points d'entr√©e `call_llm` et `call_llm_stream`, garantissant que tous les appels LLM, quelle que soit leur cat√©gorie (d√©cisionnel, outils, output), sont trac√©s.
        *   **Statut :** IMPL√âMENT√â.
    
    *   **Am√©lioration de la Visualisation des √âvaluations LLM : Ajout du Mod√®le et du Contexte**
        *   **Analyse :** La fonctionnalit√© de visualisation des r√©sultats d'√©valuation √©tait fonctionnelle mais incompl√®te. Elle n'affichait pas les informations cruciales que sont le nom du mod√®le et la taille de la fen√™tre de contexte utilis√©s pour chaque test, rendant les r√©sultats difficiles √† comparer et √† interpr√©ter.
        *   **R√©solution :** L'impl√©mentation a √©t√© r√©alis√©e sur l'ensemble de la pile. **1. Backend :** La colonne `llm_context_window` a √©t√© ajout√©e √† la table `llm_evaluation_runs` via un mod√®le (`sql_models.py`) et une migration Alembic. Les sch√©mas Pydantic (`settings_schema.py`) ont √©t√© mis √† jour pour recevoir et retourner cette donn√©e, et la fonction CRUD (`crud_settings.py`) a √©t√© adapt√©e pour la sauvegarder. **2. Frontend :** L'appel API dans `api.js` a √©t√© modifi√© pour inclure la fen√™tre de contexte. Le gestionnaire d'√©v√©nements dans `events.js` a √©t√© corrig√© pour lire la valeur du champ de contexte et la passer √† l'API. Enfin, la fonction de rendu dans `ui.js` a √©t√© mise √† jour pour afficher les nouvelles colonnes "Model Name" et "Context" dans le tableau des r√©sultats.
        *   **Statut :** IMPL√âMENT√â.
    
    *   **Visualisation des R√©sultats d'√âvaluation des Mod√®les LLM**
        *   **Analyse :** La fonctionnalit√© d'√©valuation des LLM a √©t√© impl√©ment√©e, mais il n'existait aucun moyen de visualiser l'historique des r√©sultats, rendant la fonctionnalit√© incompl√®te.
        *   **R√©solution :** L'historique des √©valuations est maintenant consultable directement depuis l'interface. **1. Backend :** Un nouveau sch√©ma Pydantic (`LLMEvaluationRunResult`) a √©t√© cr√©√© dans `app/schemas/settings_schema.py`. Une fonction CRUD `get_llm_evaluation_runs_by_category` a √©t√© ajout√©e √† `app/database/crud_settings.py` pour r√©cup√©rer les donn√©es. Un nouvel endpoint `GET /api/settings/llm/evaluations/{llm_category}` a √©t√© impl√©ment√© dans `app/api/settings_api.py` pour exposer ces donn√©es. **2. Frontend :** Une fonction d'appel `fetchLLMEvaluationResults` a √©t√© ajout√©e √† `frontend/src/api.js`. Dans `frontend/src/ui.js`, la logique d'affichage a √©t√© cr√©√©e via une nouvelle fonction `renderEvaluationResults`. Un bouton "View Results" a √©t√© ajout√© aux blocs de configuration LLM, avec un gestionnaire d'√©v√©nements qui d√©clenche l'appel API et affiche les r√©sultats dans un tableau, avec un comportement de bascule (afficher/masquer).
        *   **Statut :** IMPL√âMENT√â.
    
    *   **Impl√©mentation de l'√âvaluation des Mod√®les LLM (Backend & Frontend)**
        *   **Analyse :** Un besoin a √©t√© identifi√© pour tester objectivement la fiabilit√© et la performance des mod√®les LLM locaux directement depuis l'interface GroBot. L'objectif √©tait de simuler une charge de travail r√©aliste en faisant varier la taille du contexte et la fen√™tre de contexte maximale allou√©e.
        *   **R√©solution :** La fonctionnalit√© a √©t√© impl√©ment√©e de bout en bout. **1. Correctif Pr√©alable :** Un bug emp√™chant la prise en compte du param√®tre `context_window` a √©t√© corrig√© dans `app/core/llm_manager.py`. **2. Backend (Base de Donn√©es) :** Une nouvelle table `llm_evaluation_runs` a √©t√© cr√©√©e via un mod√®le dans `app/database/sql_models.py` et une migration Alembic pour stocker les r√©sultats. **3. Backend (API & Worker) :** Un nouvel endpoint `POST /api/settings/llm/evaluate` a √©t√© cr√©√© dans `app/api/settings_api.py` pour lancer les √©valuations. Il utilise de nouveaux sch√©mas Pydantic (`app/schemas/settings_schema.py`) et une fonction CRUD (`app/database/crud_settings.py`) pour cr√©er une t√¢che en base de donn√©es avant de la d√©l√©guer √† Celery. Une nouvelle t√¢che `run_llm_evaluation` a √©t√© ajout√©e dans `app/worker/tasks.py`, contenant la logique de test (double boucle, gestion d'√©tat, sauvegarde des r√©sultats). **4. Frontend (Interface & Logique) :** Un bouton "Evaluate" a √©t√© ajout√© aux blocs de configuration LLM dans `frontend/src/ui.js`. Une fonction `startLLMEvaluation` a √©t√© cr√©√©e dans `frontend/src/api.js` pour appeler le nouvel endpoint. Enfin, la logique de gestion du clic a √©t√© impl√©ment√©e dans `frontend/src/events.js` et connect√©e dans `frontend/src/main.js`.
        *   **Statut :** IMPL√âMENT√â.
    
    ### 7.3. Bugs R√©cemment R√©solus
    
    *   **√âchec de l'Ex√©cution des Workflows avec Outils Asynchrones (Streaming)**
        *   **Analyse :** Les workflows utilisant des outils asynchrones (ex: `generate_image`) √©chouaient syst√©matiquement. L'investigation a r√©v√©l√© une incompatibilit√© de protocole dans la t√¢che Celery `execute_workflow`. Le worker effectuait un appel HTTP synchrone et attendait une r√©ponse directe, alors que le serveur d'outils (MCP) r√©pondait avec un message `stream/start` pour initier une connexion WebSocket, conform√©ment au standard pour les t√¢ches longues. La logique du worker interpr√©tait cette r√©ponse de streaming valide comme une erreur, car elle ne contenait pas la cl√© `"result"` attendue, provoquant un `ValueError`.
        *   **R√©solution :** Le bug a √©t√© corrig√© en rendant la t√¢che `execute_workflow` (`app/worker/tasks.py`) "consciente du streaming". La logique de gestion de la r√©ponse MCP a √©t√© enti√®rement revue pour traiter trois cas distincts : une r√©ponse d'erreur, une r√©ponse synchrone contenant une cl√© `"result"`, ou une r√©ponse de d√©marrage de streaming (`{"method": "stream/start"}`). Dans ce dernier cas, la t√¢che extrait maintenant l'URL WebSocket (`ws_url`) de la r√©ponse et utilise la fonction asynchrone existante `_handle_mcp_stream` pour se connecter au stream, attendre et r√©cup√©rer le r√©sultat final de l'outil. De plus, la m√©canique de nouvelle tentative automatique (`retry`) sur √©chec a √©t√© supprim√©e, car les erreurs de workflow sont g√©n√©ralement d√©terministes.
        *   **Statut :** R√âSOLU.
    
    *   **Non-lancement des Workflows (Manuels et Cron)**
        *   **Analyse :** Les workflows ne se lan√ßaient pas du tout. Les logs du worker Celery montraient que la t√¢che `execute_workflow` se terminait avec succ√®s en 1ms, car son contenu avait √©t√© accidentellement supprim√©. De plus, la planification (cron) n'√©tait pas impl√©ment√©e.
        *   **R√©solution :** Une s√©rie de correctifs a √©t√© appliqu√©e. **1. R√©-impl√©mentation :** La logique compl√®te de `execute_workflow` a √©t√© restaur√©e dans `app/worker/tasks.py`. **2. Impl√©mentation du Cron :** Une nouvelle t√¢che `schedule_cron_workflows` a √©t√© cr√©√©e pour scanner et lancer les workflows planifi√©s, et le `beat_schedule` a √©t√© configur√© dans `app/worker/celery_app.py` pour l'ex√©cuter toutes les minutes. **3. D√©pendances :** La librairie `croniter` a √©t√© ajout√©e √† `requirements.txt`. **4. D√©bogage It√©ratif :** Plusieurs `AttributeError` et `UnsupportedProtocol` ont √©t√© corrig√©s en reconstruisant correctement l'URL des serveurs MCP. Des erreurs de validation de type (string vs list) ont √©t√© corrig√©es en ajoutant une logique de transformation de donn√©es dans le worker pour les outils `generate_prompt` et `generate_image`.
        *   **Statut :** R√âSOLU (remplac√© par un bug plus sp√©cifique).
    
    *   **Anonymat de l'Historique de Conversation**
        *   **Analyse :** Les nouveaux logs LLM ont r√©v√©l√© un bug critique : l'historique des conversations envoy√© au LLM anonymisait tous les participants sous le r√¥le g√©n√©rique "user". Le LLM √©tait incapable de distinguer qui parlait, ce qui l'emp√™chait de suivre des conversations multi-utilisateurs et de r√©pondre de mani√®re contextuelle.
        *   **R√©solution :** Une correction a √©t√© appliqu√©e sur l'ensemble de la cha√Æne de donn√©es. **1. Sch√©ma :** Le champ optionnel `name` a √©t√© ajout√© au sch√©ma `ChatMessage` dans `app/schemas/chat_schemas.py`. **2. Client Discord :** La fonction `_fetch_history` dans `discord_bot_launcher/client/event_handler.py` a √©t√© modifi√©e pour r√©cup√©rer et inclure le `display_name` de chaque auteur de message. **3. Logging :** La fonction `log_llm_interaction` dans `app/core/llm_manager.py` a √©t√© mise √† jour pour afficher ce nouveau nom, rendant les logs lisibles et confirmant le correctif.
        *   **Statut :** R√âSOLU.
    
    *   **Fen√™tre de Contexte non Sauvegard√©e lors de l'√âvaluation LLM**
        *   **Analyse :** Apr√®s la mise en place de l'interface pour l'ajout de la fen√™tre de contexte, il a √©t√© constat√© que la valeur n'√©tait pas enregistr√©e. La colonne "Context" dans les r√©sultats affichait syst√©matiquement "N/A". L'investigation a montr√© que le gestionnaire d'√©v√©nements JavaScript ne lisait pas la valeur de ce nouveau champ avant de lancer l'appel API.
        *   **R√©solution :** Le bug a √©t√© corrig√© dans la fonction `handleEvaluateLlm` du fichier `frontend/src/events.js`. La fonction a √©t√© modifi√©e pour lire l'attribut `data-context-field-id` du bouton, r√©cup√©rer la valeur de l'input correspondant et l'inclure dans la charge utile de la requ√™te envoy√©e √† l'API.
        *   **Statut :** R√âSOLU.
    
    *   **√âchec de l'√âvaluation LLM et Cascade d'Erreurs Associ√©es**
        *   **Analyse :** Le sympt√¥me initial √©tait une erreur 404 "Not Found" lors du clic sur le bouton "Evaluate". L'enqu√™te a r√©v√©l√© une cascade d'erreurs √† plusieurs niveaux. La cause de la 404 √©tait que l'endpoint `/api/settings/llm/evaluate` √©tait compl√®tement manquant dans `app/api/settings_api.py`. Apr√®s sa r√©int√©gration, une `TypeError` a √©t√© d√©clench√©e car l'API appelait la t√¢che Celery avec des arguments incorrects. Une fois ce probl√®me corrig√©, une `AttributeError` est apparue dans le worker car il tentait d'importer un mod√®le SQLAlchemy depuis le mauvais module. Le dernier obstacle √©tait une `ConnectionError`, car le conteneur du worker ne parvenait pas √† joindre le serveur Ollama. La cause en √©tait une configuration r√©seau manquante (`extra_hosts`) pour le service `worker` dans `docker-compose.yml`. Parall√®lement, un bug de r√©gression a √©t√© d√©couvert : le bouton "Save Changes" des param√®tres globaux √©tait inop√©rant √† cause d'une `TypeError` JavaScript, due √† une incoh√©rence entre les noms de champs g√©n√©r√©s dans `ui.js` et ceux lus dans `events.js`.
        *   **R√©solution :** Une s√©rie de correctifs a √©t√© appliqu√©e sur l'ensemble de la pile. **1. API (`app/api/settings_api.py`) :** L'endpoint manquant a √©t√© r√©impl√©ment√© et l'appel √† la t√¢che Celery a √©t√© corrig√© pour utiliser un dictionnaire unique, correspondant √† la signature attendue. **2. Worker (`app/worker/tasks.py`) :** L'importation du mod√®le `LLMEvaluationRun` a √©t√© corrig√©e pour pointer vers `app/database/sql_models.py`. **3. Frontend (`frontend/src/ui.js`) :** Les noms de cat√©gories LLM ('tool', 'output') dans la fonction de rendu du formulaire ont √©t√© corrig√©s pour correspondre √† ceux attendus par le gestionnaire d'√©v√©nements, r√©parant ainsi le bouton de sauvegarde. **4. Orchestration (`docker-compose.yml`) :** La directive `extra_hosts` a √©t√© ajout√©e aux services `worker` et `celery-beat` pour leur permettre de r√©soudre `host.docker.internal` et de se connecter au serveur Ollama, r√©solvant ainsi l'erreur de connexion finale.
        *   **Statut :** R√âSOLU.
    
    ### 7.4. Points d'Am√©lioration Potentiels (Code/Architecture)
    
    *   **Standardiser les Sorties d'Outils avec `outputSchema` :** Pour r√©soudre le bug d'ex√©cution des workflows et am√©liorer radicalement l'UX de l'√©diteur, il est n√©cessaire d'√©tendre la d√©finition des outils MCP pour inclure un `outputSchema`. Cela permettra √† l'application de conna√Ætre de mani√®re d√©terministe la structure des donn√©es retourn√©es par un outil, fiabilisant la liaison des donn√©es et permettant une interface utilisateur intuitive.
    
    *   **Backend Implementation for Categorized LLM Configuration (`app/database/sql_models.py`, `app/schemas/*`, `app/api/*`)**
        *   **Description :** Le frontend a √©t√© mis √† jour pour permettre la configuration de mod√®les LLM par cat√©gorie (D√©cisionnel, Outils, Output). Le backend doit maintenant √™tre adapt√© pour supporter cette nouvelle structure (migration de base de donn√©es, mise √† jour des sch√©mas Pydantic et des endpoints, refactorisation de l'orchestrateur).
        *   **Impact :** La nouvelle configuration LLM n'est pas pleinement fonctionnelle tant que le backend n'est pas mis √† jour.
    
    *   **Am√©liorer la Gestion de l'Identit√© Utilisateur via un Syst√®me de Profils**
        *   **Probl√©matique :** L'impl√©mentation actuelle envoie le `display_name` de l'utilisateur dans le prompt du LLM. C'est optimal pour la compr√©hension du mod√®le en langage naturel, mais cette donn√©e est volatile. Si un utilisateur change de pseudo, le bot perd le lien avec l'historique de ses connaissances sur cette personne, ce qui fragilise sa m√©moire √† long terme.
        *   **Solution Propos√©e :**
            *   Ancrer l'identit√© de chaque utilisateur √† son **ID Discord**, qui est unique et immuable.
            *   Cr√©er une nouvelle table en base de donn√©es (ex: `user_profiles`) avec l'ID Discord comme cl√© primaire.
            *   Cette table stockera des informations enrichies : le pseudo actuel (`current_display_name`), une liste des anciens pseudos connus (`known_aliases`), et une liste de surnoms (`nicknames`).
            *   Mettre en place une logique qui, √† chaque interaction, compare le pseudo actuel de l'utilisateur avec celui stock√©. En cas de diff√©rence, le syst√®me met √† jour le pseudo actuel et archive l'ancien dans la liste des alias.
        *   **Impact et B√©n√©fices :**
            *   **Fiabilit√© de la M√©moire :** Le bot reconna√Ætra les utilisateurs de mani√®re permanente, m√™me s'ils changent de pseudo.
            *   **Contexte Enrichi :** Ouvre la possibilit√© d'interactions plus personnelles et contextuelles (ex: "Je vois que tu as chang√© de nom, je te connaissais en tant que 'AncienPseudo'").
            *   **Fondation Solide :** Cr√©e la base n√©cessaire pour impl√©menter de futures fonctionnalit√©s li√©es aux pr√©f√©rences et au profil de chaque utilisateur.
    
    ---
    
    ### 7.5. Plan d'Action pour la Prochaine Session
    
    *   **T√¢che Prioritaire : R√©soudre le bug de pr√©-remplissage de l'√©diteur de workflow.**
        *   **Description :** Maintenant que l'ex√©cution des workflows est stable, nous pouvons nous concentrer sur le bug de l'interface utilisateur. Lors de l'√©dition d'un workflow, la derni√®re √©tape n'affiche pas ses param√®tres. La prochaine session se concentrera sur le d√©bogage de `frontend/src/workflow_editor.js` et des fichiers associ√©s (`ui.js`, `api.js`) pour r√©soudre ce probl√®me d'affichage.
    
    ---
    
    ## 8. ANNEXE : Anciennes Architectures d'Agent (Obsol√®tes)
    
    > **ATTENTION :** Cette section d√©crit les anciennes architectures qui ne sont plus en production. Elle est conserv√©e √† titre de r√©f√©rence historique uniquement.
    
    ### 8.1. Architecture "Cha√Æne de Montage" Asynchrone (Session 96-121)
    
    Cette architecture utilisait une cha√Æne de 4 LLM (Gardien, R√©partiteur, Synth√©tiseur, Archiviste) principalement orchestr√©e par le client `bot_process.py`. Le client g√©rait la d√©cision d'utiliser des outils, leur ex√©cution (interne ou via proxy), et l'envoi des r√©sultats au Synth√©tiseur. Elle a √©t√© remplac√©e car la logique de d√©cision √©tait trop monolithique (un seul "R√©partiteur") et la gestion de la boucle d'outils par le client √©tait trop complexe.
    
    ### 8.2. Architecture Monolithique (Pr√©-Session 96)
    
    Cette architecture initiale reposait sur un unique appel LLM avec une liste d'outils au format `ollama-python`. Le client `bot_process.py` √©tait responsable de la gestion compl√®te de la boucle "appel LLM -> d√©tection d'appel d'outil -> ex√©cution de l'outil -> second appel LLM avec le r√©sultat". Elle a √©t√© abandonn√©e en raison de sa faible fiabilit√© pour les t√¢ches complexes et du manque de contr√¥le sur le raisonnement du LLM.