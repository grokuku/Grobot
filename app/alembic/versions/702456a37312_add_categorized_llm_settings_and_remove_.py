"""Add categorized LLM settings and remove old fields

Revision ID: 702456a37312
Revises: 793eb6a56ac3
Create Date: 2025-09-29 15:21:56.859788

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '702456a37312'
down_revision: Union[str, Sequence[str], None] = '793eb6a56ac3'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('bots', sa.Column('decisional_llm_server_url', sa.String(), nullable=True))
    op.add_column('bots', sa.Column('decisional_llm_model', sa.String(), nullable=True))
    op.add_column('bots', sa.Column('decisional_llm_context_window', sa.Integer(), nullable=True))
    op.add_column('bots', sa.Column('tools_llm_server_url', sa.String(), nullable=True))
    op.add_column('bots', sa.Column('tools_llm_model', sa.String(), nullable=True))
    op.add_column('bots', sa.Column('tools_llm_context_window', sa.Integer(), nullable=True))
    op.add_column('bots', sa.Column('output_client_llm_server_url', sa.String(), nullable=True))
    op.add_column('bots', sa.Column('output_client_llm_model', sa.String(), nullable=True))
    op.add_column('bots', sa.Column('output_client_llm_context_window', sa.Integer(), nullable=True))
    op.add_column('bots', sa.Column('multimodal_llm_model', sa.String(), nullable=True))
    op.drop_column('bots', 'custom_ollama_host_url')
    op.drop_column('bots', 'llm_model')
    op.drop_column('bots', 'llm_context_window')
    op.drop_column('bots', 'use_custom_ollama')
    op.add_column('global_settings', sa.Column('decisional_llm_server_url', sa.String(), nullable=False, server_default='http://host.docker.internal:11434'))
    op.add_column('global_settings', sa.Column('decisional_llm_model', sa.String(), nullable=False, server_default='llama3'))
    op.add_column('global_settings', sa.Column('decisional_llm_context_window', sa.Integer(), nullable=False, server_default='4096'))
    op.add_column('global_settings', sa.Column('tools_llm_server_url', sa.String(), nullable=False, server_default='http://host.docker.internal:11434'))
    op.add_column('global_settings', sa.Column('tools_llm_model', sa.String(), nullable=False, server_default='llama3'))
    op.add_column('global_settings', sa.Column('tools_llm_context_window', sa.Integer(), nullable=False, server_default='8192'))
    op.add_column('global_settings', sa.Column('output_client_llm_server_url', sa.String(), nullable=False, server_default='http://host.docker.internal:11434'))
    op.add_column('global_settings', sa.Column('output_client_llm_model', sa.String(), nullable=False, server_default='llama3'))
    op.add_column('global_settings', sa.Column('output_client_llm_context_window', sa.Integer(), nullable=False, server_default='16384'))
    op.drop_column('global_settings', 'ollama_host_url')
    op.drop_column('global_settings', 'default_llm_model')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('global_settings', sa.Column('default_llm_model', sa.VARCHAR(), server_default=sa.text("'llama3'::character varying"), autoincrement=False, nullable=False))
    op.add_column('global_settings', sa.Column('ollama_host_url', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.drop_column('global_settings', 'output_client_llm_context_window')
    op.drop_column('global_settings', 'output_client_llm_model')
    op.drop_column('global_settings', 'output_client_llm_server_url')
    op.drop_column('global_settings', 'tools_llm_context_window')
    op.drop_column('global_settings', 'tools_llm_model')
    op.drop_column('global_settings', 'tools_llm_server_url')
    op.drop_column('global_settings', 'decisional_llm_context_window')
    op.drop_column('global_settings', 'decisional_llm_model')
    op.drop_column('global_settings', 'decisional_llm_server_url')
    op.add_column('bots', sa.Column('use_custom_ollama', sa.BOOLEAN(), autoincrement=False, nullable=False))
    op.add_column('bots', sa.Column('llm_context_window', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('bots', sa.Column('llm_model', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('bots', sa.Column('custom_ollama_host_url', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.drop_column('bots', 'multimodal_llm_model')
    op.drop_column('bots', 'output_client_llm_context_window')
    op.drop_column('bots', 'output_client_llm_model')
    op.drop_column('bots', 'output_client_llm_server_url')
    op.drop_column('bots', 'tools_llm_context_window')
    op.drop_column('bots', 'tools_llm_model')
    op.drop_column('bots', 'tools_llm_server_url')
    op.drop_column('bots', 'decisional_llm_context_window')
    op.drop_column('bots', 'decisional_llm_model')
    op.drop_column('bots', 'decisional_llm_server_url')
    # ### end Alembic commands ###