"""Add llm_evaluation_runs table

Revision ID: b48e99e33d8e
Revises: f88b6ee547df
Create Date: 2025-10-09 09:39:30.110233

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'b48e99e33d8e'
down_revision: Union[str, Sequence[str], None] = 'f88b6ee547df'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('llm_evaluation_runs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('task_id', sa.String(), nullable=False, comment='The Celery task ID for this run.'),
    sa.Column('status', sa.String(), nullable=False, comment='The current status of the evaluation (e.g., PENDING, RUNNING, COMPLETED, FAILED).'),
    sa.Column('llm_category', sa.String(), nullable=False, comment='The category of the LLM task being evaluated (e.g., decisional, tools, output_client).'),
    sa.Column('llm_server_url', sa.String(), nullable=False, comment='The URL of the LLM server used for the evaluation.'),
    sa.Column('llm_model_name', sa.String(), nullable=False, comment='The name of the model being evaluated.'),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('now()'), nullable=True),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('summary_reliability_score', sa.Float(), nullable=True, comment='Overall reliability score (e.g., percentage of passed tests).'),
    sa.Column('summary_avg_response_ms', sa.Float(), nullable=True, comment='Average response time in milliseconds across all tests.'),
    sa.Column('summary_avg_tokens_per_second', sa.Float(), nullable=True, comment='Average tokens per second, mainly for generative tasks.'),
    sa.Column('results_data', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='A JSON object containing detailed results for each individual test case.'),
    sa.Column('error_message', sa.Text(), nullable=True, comment='Stores any terminal error message if the entire run fails.'),
    sa.CheckConstraint("status IN ('PENDING', 'RUNNING', 'COMPLETED', 'FAILED')", name='llm_evaluation_run_status_check'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_llm_evaluation_runs_llm_category'), 'llm_evaluation_runs', ['llm_category'], unique=False)
    op.create_index(op.f('ix_llm_evaluation_runs_llm_model_name'), 'llm_evaluation_runs', ['llm_model_name'], unique=False)
    op.create_index(op.f('ix_llm_evaluation_runs_status'), 'llm_evaluation_runs', ['status'], unique=False)
    op.create_index(op.f('ix_llm_evaluation_runs_task_id'), 'llm_evaluation_runs', ['task_id'], unique=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_llm_evaluation_runs_task_id'), table_name='llm_evaluation_runs')
    op.drop_index(op.f('ix_llm_evaluation_runs_status'), table_name='llm_evaluation_runs')
    op.drop_index(op.f('ix_llm_evaluation_runs_llm_model_name'), table_name='llm_evaluation_runs')
    op.drop_index(op.f('ix_llm_evaluation_runs_llm_category'), table_name='llm_evaluation_runs')
    op.drop_table('llm_evaluation_runs')
    # ### end Alembic commands ###
