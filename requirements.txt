# Framework Backend
fastapi>=0.115.0
uvicorn[standard]>=0.34.0
websockets>=14.0

# Tâches asynchrones
celery>=5.4.0
redis>=5.2.0
croniter>=6.0.0

# Base de données
sqlalchemy>=2.0.36
psycopg[binary]>=3.2.0

# Validation et Configuration (Crucial pour LiteLLM)
pydantic>=2.10.0
pydantic-settings>=2.7.0

# Clients HTTP & Outils
httpx>=0.28.0
jinja2>=3.1.5
python-multipart>=0.0.20
requests>=2.32.0

# Traitement de fichiers
python-magic>=0.4.27
Pillow>=11.0.0

# IA & Vector Database
chromadb-client>=0.6.0
tokenizers>=0.21.0
onnxruntime>=1.20.0

# --- LLM Stack (MODERNISÉE) ---
# Ollama
ollama>=0.5.0

# LiteLLM & OpenAI (Couplage fort pour les types)
# L'ajout explicite de openai assure la compatibilité des objets Response
openai>=1.60.0
litellm>=1.60.0

# --- Frameworks Spécifiques ---
# Agentic Context Engine
ace-framework

# --- MCP Standard Libraries ---
mcp>=1.1.0
mcp-use>=0.2.0